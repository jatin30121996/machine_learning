{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5492f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0ac3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(4, name=\"layer3\"),\n",
    "])\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93096b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaab4abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x114893de430>,\n",
       " <keras.layers.core.Dense at 0x114893d0220>,\n",
       " <keras.layers.core.Dense at 0x114893d0670>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation=\"relu\"),\n",
    "    layers.Dense(3, activation=\"relu\"),\n",
    "    layers.Dense(4),\n",
    "])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1412bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c534f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6ce8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"my_sequential\")\n",
    "model.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
    "model.add(layers.Dense(4, name=\"layer3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc7eeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.3539014 , -0.6499318 , -0.51072717],\n",
       "        [ 0.8198241 , -0.18924189,  0.16388035],\n",
       "        [-0.15228397,  0.44613588,  0.14234054],\n",
       "        [-0.34849173, -0.4893662 , -0.55039   ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8103c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation=\"relu\"),\n",
    "    layers.Dense(3, activation=\"relu\"),\n",
    "    layers.Dense(4),\n",
    "])\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f2c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (1, 2)                    10        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (1, 3)                    9         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (1, 4)                    16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7caa41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4, )))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7678f8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x11489199cd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "708cf022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\", input_shape=(4,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dfa88d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.summary()\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "model.summary()\n",
    "\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8979241",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential([\n",
    "    keras.Input(shape=(250, 250, 3)),\n",
    "    layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "])\n",
    "feature_extractor = keras.Model(inputs=initial_model.inputs, outputs=[layer.output for layer in initial_model.layers])\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa591922",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential([\n",
    "    keras.Input(shape=(250, 250, 3)),\n",
    "    layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\")\n",
    "])\n",
    "feature_extractor = keras.Model(inputs=initial_model.inputs,\n",
    "                                outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output)\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dab0b2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c0f4b57b1a55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m ])\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2327\u001b[0m           'True when by_name is True.')\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2329\u001b[1;33m     \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_detect_save_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2331\u001b[0m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_detect_save_format\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m   3006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3007\u001b[0m   \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3008\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3009\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\saving_utils.py\u001b[0m in \u001b[0;36mis_hdf5_filepath\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_hdf5_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[0;32m    321\u001b[0m           filepath.endswith('.hdf5'))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "model.load_weights(...)\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a4293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 604s 7us/step\n",
      "83697664/83683744 [==============================] - 604s 7us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: Ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3e30f9d7bc3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m ])\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[0;32m    560\u001b[0m           loss, loss_weights, output_names=self.output_names)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    594\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m       \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m       if (loss_scale is not None and\n\u001b[0;32m    589\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    133\u001b[0m         'Could not interpret optimizer identifier: {}'.format(identifier))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: Ellipsis"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights = \"imagenet\",\n",
    "    include_top=False,\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base_model.trainable = False\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(1000),\n",
    "])\n",
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90582b56",
   "metadata": {},
   "source": [
    "# The Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc912912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a655fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,))\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35207c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 0.3385 - accuracy: 0.9028 - val_loss: 0.1845 - val_accuracy: 0.9461\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.1595 - accuracy: 0.9528 - val_loss: 0.1395 - val_accuracy: 0.9597\n",
      "313/313 - 0s - loss: 0.1333 - accuracy: 0.9603\n",
      "Test loss: 0.13330422341823578\n",
      "Test accuracy: 0.9603000283241272\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\")/255\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=keras.optimizers.RMSprop(), metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0f6ad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "384d30cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"path_to_my_model\")\n",
    "del model\n",
    "model = keras.models.load_model(\"path_to_my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f776e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_6 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"wutoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_6 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decode_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "autoencoder = keras.Model(encoder_input, decode_output, name=\"wutoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe2a606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "original_img (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_10 (Glo (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DT (None, 26, 26, 1)         289       \n",
      "=================================================================\n",
      "Total params: 5,089\n",
      "Trainable params: 5,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 26, 26, 1)         5089      \n",
      "=================================================================\n",
      "Total params: 23,761\n",
      "Trainable params: 23,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb024aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128, ))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "467f9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12\n",
    "num_words = 10000\n",
    "num_departments = 4\n",
    "title_input = keras.Input(shape=(None, ), name=\"title\")\n",
    "body_input = keras.Input(shape=(None, ), name=\"body\")\n",
    "tags_input = keras.Input(shape=(num_tags, ), name=\"tags\")\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "model = keras.Model(inputs=[title_input, body_input, tags_input], \n",
    "                   outputs = [priority_pred, department_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aed2470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=[keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "                  keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
    "             loss_weights=[1.0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55e6fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss={\n",
    "    \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    \"department\":keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "},\n",
    "loss_weights={\"priority\":1.0, \"department\":0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da3b3ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40/40 [==============================] - 8s 54ms/step - loss: 1.2955 - priority_loss: 0.6983 - department_loss: 2.9857\n",
      "Epoch 2/2\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 1.2859 - priority_loss: 0.6962 - department_loss: 2.9485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1148b278400>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "model.fit({\"title\":title_data, \"body\":body_data, \"tags\":tags_data}, \n",
    "         {\"priority\":priority_targets, \"department\":dept_targets},\n",
    "         epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a428014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 28, 28, 64)   18496       conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 9, 9, 64)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 9, 9, 64)     0           conv2d_89[0][0]                  \n",
      "                                                                 max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 9, 9, 64)     36928       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 9, 9, 64)     0           conv2d_91[0][0]                  \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 64)     36928       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 256)          16640       global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 10)           2570        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93f7137a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-82c43d9b0f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\datasets\\cifar10.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[0mdirname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cifar-10-batches-py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m   \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m   path = get_file(\n\u001b[0m\u001b[0;32m     80\u001b[0m       \u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m       \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mchunk_read\u001b[1;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[0;32m     71\u001b[0m       \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreporthook\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) =keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test = x_test.astype(\"float32\")/255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"acc\"])\n",
    "model.fit(x_train[:1000], y_train[:1000], batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc73cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "text_input_a = keras.Input(shape=(None, ), dtype=\"int32\")\n",
    "text_input_b = keras.Input(shape=(None, ), dtype=\"int32\")\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "034c560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 672s 1us/step\n",
      "574726144/574710816 [==============================] - 672s 1us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = tf.keras.applications.VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb1e15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [layer.output for layer in vgg19.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5594551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
    "img = np.random.random((1, 224, 224, 3)).astype(\"float32\")\n",
    "extracted_features = feat_extraction_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f348ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "    \n",
    "inputs = keras.Input((4, ))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558bf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape = (input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}\n",
    "    \n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = keras.Model.from_config(config, custom_objects={\"CustomDense\":CustomDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035d4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32,))\n",
    "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10)(x)\n",
    "mlp = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6407fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.dense_1 = layers.Dense(64, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(10)\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "mlp = MLP()\n",
    "_ = mlp(tf.zeros((1, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4822525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 32)\n"
     ]
    }
   ],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "inputs = keras.Input((None, units))\n",
    "x = layers.GlobalAveragePooling1D()(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.classifier = model\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        print(features.shape)\n",
    "        return self.classifier(features)\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83216d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 32)\n"
     ]
    }
   ],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "batch_size = 16\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.classifier = layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis = 1)\n",
    "        return self.classifier(features)\n",
    "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "x = layers.Conv1D(32, 3)(inputs)\n",
    "outputs = CustomRNN()(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "rnn_mdel = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, 10, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164af178",
   "metadata": {},
   "source": [
    "# Training and evaluation with the built-in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0785854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ecbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99179bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\")/255\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc3c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(), \n",
    "             loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=[keras.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf231bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3387 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9371\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.9589\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0d4481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.33871322870254517, 0.15987689793109894],\n",
       " 'sparse_categorical_accuracy': [0.9045000076293945, 0.9525200128555298],\n",
       " 'val_loss': [0.20805248618125916, 0.1458704173564911],\n",
       " 'val_sparse_categorical_accuracy': [0.9370999932289124, 0.958899974822998]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bf76fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on the test data\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9540\n",
      "test loss, test acc: [0.15023291110992432, 0.9539999961853027]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape (3, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on the test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23227062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c26735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4816c7af0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true-y_pred))\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f44cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.0391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4819c8580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf666e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3432 - categorical_true_positives: 45275.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1645 - categorical_true_positives: 47543.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1204 - categorical_true_positives: 48194.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c481ccb1f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):F\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "    \n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics = [CategoricalTruePositives()])\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1526a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c481d8b460>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs\n",
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ecd5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3399 - std_of_activation: 1.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c487c54850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_metric(keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "        return inputs\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = MetricLoggingLayer()(x)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df33c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 2.5221 - std_of_activation: 0.0020A: 0s - loss: 2.8306 - std_of_activatio - ETA: 0s - loss: 2.5573 - std_of_activation: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c488d88ac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), \n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce25382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1685b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9688 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c488eb1c70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = keras.Input(shape=(3, ), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")\n",
    "data = {\n",
    "    \"inputs\":np.random.random((3, 3)),\n",
    "    \"targets\":np.random.random((3, 10))\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f320d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 2ms/step - loss: 0.3865 - sparse_categorical_accuracy: 0.8898 - val_loss: 0.2458 - val_sparse_categorical_accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c488fab4f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7046078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3465 - sparse_categorical_accuracy: 0.9022\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9521\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9653\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1234 - sparse_categorical_accuracy: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.12337513267993927,\n",
       " 'sparse_categorical_accuracy': 0.9620000123977661}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "model.fit(train_dataset, epochs=3)\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78aa8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.8183 - sparse_categorical_accuracy: 0.7883\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3633 - sparse_categorical_accuracy: 0.8977\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3212 - sparse_categorical_accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4819c18e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75270774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.2059 - val_sparse_categorical_accuracy: 0.9399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4818a0b20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9d1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3312 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.2660 - val_sparse_categorical_accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4818a0c40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1655bf0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b0559e62ad4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCIFAR10Sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequence' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([resize(imread(filename), (200, 200)) for filename in batch_x]), np.array(batch_y)\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602cd736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 2s 1ms/step - loss: 0.3741 - sparse_categorical_accuracy: 0.9009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48c1aa370>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_weight = {\n",
    "    0:1.0,\n",
    "    1:1.0,\n",
    "    2:1.0,\n",
    "    3:1.0,\n",
    "    4:1.0,\n",
    "    5:2.0,\n",
    "    6:1.0,\n",
    "    7:1.0,\n",
    "    8:1.0,\n",
    "    9:1.0,\n",
    "}\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eacbaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3636 - sparse_categorical_accuracy: 0.903 - 1s 1ms/step - loss: 0.3597 - sparse_categorical_accuracy: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48d298610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d8fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3604 - sparse_categorical_accuracy: 0.9053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48d3a0880>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d444ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "x1 = layers.Conv2D(3, 3)(image_input)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)\n",
    "x = layers.concatenate([x1, x2])\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)\n",
    "model = keras.Model(inputs=[image_input, timeseries_input], outputs=[score_output, class_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f738ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=[keras.losses.MeanSquaredError(),\n",
    "                                                              keras.losses.CategoricalCrossentropy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c0839e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.RMSprop(1e-3),\n",
    "        loss = [keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "        metrics=[\n",
    "            [\n",
    "                keras.metrics.MeanAbsolutePercentageError(),\n",
    "                keras.metrics.MeanAbsoluteError(),\n",
    "            ],\n",
    "            [keras.metrics.CategoricalAccuracy()]\n",
    "        ]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a5cf72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss={\n",
    "                 \"score_output\":keras.losses.MeanSquaredError(),\n",
    "                 \"class_output\":keras.losses.CategoricalCrossentropy()\n",
    "             },\n",
    "             metrics={\n",
    "                 \"score_output\":[keras.metrics.MeanAbsolutePercentageError(),\n",
    "                                keras.metrics.MeanAbsoluteError()],\n",
    "                 \"class_output\":[keras.metrics.CategoricalAccuracy()]\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a217f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss={\n",
    "                 \"score_output\":keras.losses.MeanSquaredError(),\n",
    "                 \"class_output\":keras.losses.CategoricalCrossentropy()\n",
    "             },\n",
    "             metrics={\n",
    "                 \"score_output\":[\n",
    "                     keras.metrics.MeanAbsolutePercentageError(),\n",
    "                     keras.metrics.MeanAbsoluteError()\n",
    "                 ],\n",
    "                 \"class_output\":[keras.metrics.CategoricalAccuracy()]\n",
    "             },\n",
    "             loss_weights={\"score_output\":2.0, \"class_output\":1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54e9b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=[None, keras.losses.CategoricalCrossentropy()])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss={\"class_output\":keras.losses.CategoricalCrossentropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95f3b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 9ms/step - loss: 19.2916 - score_output_loss: 0.9333 - class_output_loss: 18.3583\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18.1968 - score_output_loss: 0.6225 - class_output_loss: 17.5743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48da75670>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()])\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "model.fit({\n",
    "    \"img_input\":img_data, \"ts_input\":ts_data\n",
    "},{\n",
    "    \"score_output\":score_targets, \"class_output\":class_targets\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd911b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 17.4951 - score_output_loss: 0.6671 - class_output_loss: 16.8280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48d50c370>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"img_input\":img_data, \"ts_input\":ts_data},\n",
    "                                                  {\"score_output\":score_targets, \"class_output\":class_targets}))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c25fa881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3624 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.2188 - val_sparse_categorical_accuracy: 0.9356\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1680 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1234 - sparse_categorical_accuracy: 0.9620 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9556\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9596\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1376 - val_sparse_categorical_accuracy: 0.9614\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1521 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48c1a10a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-2,\n",
    "    patience=2,\n",
    "    verbose=1)\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce8f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fc4dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3620 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9327\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22102, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.1703 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22102 to 0.17034, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c48dda2d00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"mymodel_{epoch}\",\n",
    "    save_best_only=True,\n",
    "    moniter=\"val_loss\", \n",
    "    verbose=1)\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d94d7ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt/checkpoint\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ./ckpt/checkpoint\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-60b829e81089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating a new model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_or_restore_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m callbacks = [\n\u001b[0;32m     15\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/ckpt-loss={loss:.2f}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-60b829e81089>\u001b[0m in \u001b[0;36mmake_or_restore_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlatest_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetctime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring from\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating a new model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m   raise IOError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: ./ckpt/checkpoint\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "def make_or_restore_model():\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100)\n",
    "]\n",
    "mode.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b2f47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000, decay_rate=0.96, \n",
    "                                                          staircase=True)\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3a1a5",
   "metadata": {},
   "source": [
    "# Making new Layers and Models via subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4d93b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa7ec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"), trainable=True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(initial_value=b_init(shape=(units, ), dtype=\"float32\"), trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1bf5215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.0130002   0.02132882 -0.07102855 -0.08569014]\n",
      " [ 0.0130002   0.02132882 -0.07102855 -0.08569014]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2, 2))\n",
    "linear_layer = Linear(4, 2)\n",
    "y = linear_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21500a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert linear_layer.weights == [linear_layer.w, linear_layer.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24cabe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.0934522   0.03243705  0.04224774 -0.04856107]\n",
      " [-0.0934522   0.03243705  0.04224774 -0.04856107]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(units, ), initializer=\"zeros\", trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "x = tf.ones((2, 2))\n",
    "linear_layer = Linear(4, 2)\n",
    "y = linear_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdf2e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "[4. 4.]\n"
     ]
    }
   ],
   "source": [
    "class ComputeSum(keras.layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ComputeSum, self).__init__()\n",
    "        self.total = tf.Variable(initial_value=tf.zeros((input_dim, )), trainable=False)\n",
    "    def call(self, inputs):\n",
    "        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
    "        return self.total\n",
    "x = tf.ones((2, 2))\n",
    "my_sum = ComputeSum(2)\n",
    "y = my_sum(x)\n",
    "print(y.numpy())\n",
    "y = my_sum(x)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cc5c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: 1\n",
      "non-trainable weights: 1\n",
      "trainable_weights: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights:\", len(my_sum.weights))\n",
    "print(\"non-trainable weights:\", len(my_sum.non_trainable_weights))\n",
    "print(\"trainable_weights:\", my_sum.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db1294dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(units, ), initializer=\"zeros\", trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6989fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9886f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = Linear(32)\n",
    "y = linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89b74aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 6\n"
     ]
    }
   ],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.linear_2 = Linear(32)\n",
    "        self.linear_3 = Linear(1)\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.linear_3(x)\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9991671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityRegularizationLayer(keras.layers.Layer):\n",
    "    def __init__(self, rate=1e-2):\n",
    "        super(ActivityRegularizationLayer, self).__init__()\n",
    "        self.rate = rate\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(self.rate * tf.reduce_sum(inputs))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f5a29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(OuterLayer, self).__init__()\n",
    "        self.activity_reg = ActivityRegularizationLayer(1e-2)\n",
    "    def call(self, inputs):\n",
    "        return self.activity_reg(inputs)\n",
    "layer = OuterLayer()\n",
    "assert len(layer.losses) == 0\n",
    "_ = layer(tf.zeros(1, 1))\n",
    "assert len(layer.losses) == 1\n",
    "_ = layer(tf.zeros(1, 1))\n",
    "assert len(layer.losses) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d59c25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=0.001759471>]\n"
     ]
    }
   ],
   "source": [
    "class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(OuterLayerWithKernelRegularizer, self).__init__()\n",
    "        self.dense = keras.layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "layer = OuterLayerWithKernelRegularizer()\n",
    "_ = layer(tf.zeros((1, 1)))\n",
    "print(layer.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0fbfcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1561\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c49d4e38b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = keras.Input(shape=(3,))\n",
    "outputs = ActivityRegularizationLayer()(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0907d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f713cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.metrics: [<keras.metrics.BinaryAccuracy object at 0x000001C48DEEF0A0>]\n",
      "current accuracy value: 1.0\n"
     ]
    }
   ],
   "source": [
    "layer = LogisticEndpoint()\n",
    "targets = tf.ones((2, 2))\n",
    "logits = tf.ones((2, 2))\n",
    "y = layer(targets, logits)\n",
    "print(\"layer.metrics:\", layer.metrics)\n",
    "print(\"current accuracy value:\", float(layer.metrics[0].result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3b94e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 64}\n"
     ]
    }
   ],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    def get_config(self):\n",
    "        return {\"units\":self.units}\n",
    "layer = Linear(64)\n",
    "config = layer.get_config()\n",
    "print(config)\n",
    "new_layer = Linear.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87d6e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'linear_25', 'trainable': True, 'dtype': 'float32', 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(Linear, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", train_able=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    def get_config(self):\n",
    "        config = super(Linear, self).get_config()\n",
    "        config.update({\"units\":self.units})\n",
    "        return config\n",
    "layer = Linear(64)\n",
    "config = layer.get_config()\n",
    "print(config)\n",
    "new_layer = Linear.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e14c773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f4326e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNetBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-62bef794749e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-62bef794749e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_classes)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNetBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNetBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNetBlock' is not defined"
     ]
    }
   ],
   "source": [
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.block_1 = ResNetBlock()\n",
    "        self.block_2 = ResNetBlock()\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.classifier = Dense(num_classes)\n",
    "    def call(self, inputs):\n",
    "        x = self.block_1(inputs)\n",
    "        x = self.block_2(x)\n",
    "        x = self.global_pool(x)\n",
    "        return self.classifier(x)\n",
    "resnet = ResNet()\n",
    "dataset = ...\n",
    "resnet.fit(dataset, epochs=10)\n",
    "resnet.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64c789a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "class VariationalAutoEncoder(keras.Model):\n",
    "    def __init__(self, original_dim, intermediate_dim=64, latent_dim=32, name=\"autoencoder\", **kwargs):\n",
    "        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a42e5726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Step 0: mean loss = 0.3477\n",
      "Step 100: mean loss = 0.1258\n",
      "Step 200: mean loss = 0.0993\n",
      "Step 300: mean loss = 0.0893\n",
      "Step 400: mean loss = 0.0843\n",
      "Step 500: mean loss = 0.0809\n",
      "Step 600: mean loss = 0.0788\n",
      "Step 700: mean loss = 0.0772\n",
      "Step 800: mean loss = 0.0760\n",
      "Step 900: mean loss = 0.0750\n",
      "Start of epoch 1\n",
      "Step 0: mean loss = 0.0747\n",
      "Step 100: mean loss = 0.0740\n",
      "Step 200: mean loss = 0.0735\n",
      "Step 300: mean loss = 0.0730\n",
      "Step 400: mean loss = 0.0727\n",
      "Step 500: mean loss = 0.0723\n",
      "Step 600: mean loss = 0.0720\n",
      "Step 700: mean loss = 0.0717\n",
      "Step 800: mean loss = 0.0715\n",
      "Step 900: mean loss = 0.0712\n"
     ]
    }
   ],
   "source": [
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\")/255\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"Start of epoch %d\"%(epoch,))\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed = vae(x_batch_train)\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(vae.losses)\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "        loss_metric(loss)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step %d: mean loss = %.4f\"%(step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a851bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.0746\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c49d4ccb50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VariationalAutoEncoder(784, 64, 32)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "vae.fit(x_train, x_train, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d35efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.0693\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0676\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c49eb384c0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dim = 784\n",
    "intermediate_dim = 64\n",
    "latent_dim = 32\n",
    "original_inputs = tf.keras.Input(shape=(original_dim), name=\"encoder_input\")\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"x_log_var\")(x)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n",
    "\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation=\"sigmoid\")(x)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n",
    "\n",
    "outputs = decoder(z)\n",
    "vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n",
    "\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae.add_loss(kl_loss)\n",
    "otimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "vae.fit(x_train, x_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d479c",
   "metadata": {},
   "source": [
    "# Save and load keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef941ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9054b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7199\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d225da820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "model = get_model()\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "model.save(\"my_model\")\n",
    "reconstructed_model = keras.models.load_model(\"my_model\")\n",
    "np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ac9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2540\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d23711550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "model.save(\"my_h5_model.h5\")\n",
    "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")\n",
    "np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3f1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(3, activation=\"relu\")\n",
    "layer_config = layer.get_config()\n",
    "new_layer = keras.layers.Dense.from_config(layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5799c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "config = model.get_config()\n",
    "new_model = keras.Sequential.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15c9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input((32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c07d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "json_config = model.to_json()\n",
    "new_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a302c21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")\n",
    "tensorflow_graph = tf.saved_model.load(\"my_model\")\n",
    "x = np.random.uniform(size=(4, 32)).astype(np.float32)\n",
    "predicted = tensorflow_graph(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bab0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return inputs * self.var\n",
    "        else:\n",
    "            return inputs\n",
    "    def get_config(self):\n",
    "        return {\"a\": self.var.numpy()}\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "layer = CustomLayer(5)\n",
    "layer.var.assign(2)\n",
    "serialized_layer = keras.layers.serialize(layer)\n",
    "new_layer = keras.layers.deserialize(serialized_layer, custom_objects={\"CustomLayer\":CustomLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaef638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    def get_config(self):\n",
    "        config = super(CustomLayer, self).get_config()\n",
    "        config.update({\"units\":self.units})\n",
    "        return config\n",
    "def custom_activation(x):\n",
    "    return tf.nn.tanh(x) ** 2\n",
    "inputs = keras.Input((32,))\n",
    "x = CustomLayer(32)(inputs)\n",
    "outputs = keras.layers.Activation(custom_activation)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "custom_objects = {\"CustomLayer\":CustomLayer, \"custom_activation\":custom_activation}\n",
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2f7b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c69f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer():\n",
    "    layer = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "    layer.build((None, 784))\n",
    "    return layer\n",
    "layer_1 = create_layer()\n",
    "layer_2 = create_layer()\n",
    "layer_2.set_weights(layer_1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2c5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "class SubclassedModel(keras.Model):\n",
    "    def __init__(self, output_dim, name=None):\n",
    "        super(SubclassedModel, self).__init__(name=name)\n",
    "        self.output_dim = output_dim\n",
    "        self.dense_1 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "        self.dense_3 = keras.layers.Dense(output_dim, name=\"predictions\")\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return x\n",
    "    def get_config(self):\n",
    "        return {\"output_dim\":self.output_dim, \"name\":self.name}\n",
    "subclassed_model = SubclassedModel(10)\n",
    "subclassed_model(tf.ones((1, 784)))\n",
    "subclassed_model.set_weights(functional_model.get_weights())\n",
    "assert len(functional_model.weights) == len(subclassed_model.weights)\n",
    "for a, b in zip(functional_model.weights, subclassed_model.weights):\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b02c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs = outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model_with_dropout = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "functional_model_with_dropout.set_weights(functional_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23d27ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29d24b1bf40>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model = keras.Sequential([\n",
    "    keras.Input(shape=(784, ), name=\"digits\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "    keras.layers.Dense(10, name=\"predictions\")\n",
    "])\n",
    "sequential_model.save_weights(\"ckpt\")\n",
    "load_status = sequential_model.load_weights(\"ckpt\")\n",
    "load_status.assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be64e3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_CHECKPOINTABLE_OBJECT_GRAPH': tf.string,\n",
       " 'layer/var/.ATTRIBUTES/VARIABLE_VALUE': tf.int32,\n",
       " 'save_counter/.ATTRIBUTES/VARIABLE_VALUE': tf.int64}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "layer = CustomLayer(5)\n",
    "layer_ckpt = tf.train.Checkpoint(layer=layer).save(\"custom_layer\")\n",
    "ckpt_reader = tf.train.load_checkpoint(layer_ckpt)\n",
    "ckpt_reader.get_variable_to_dtype_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26a8bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrained_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 54,400\n",
      "Trainable params: 54,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " --------------------------------------------------\n",
      "Model: \"new_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pretrained (Functional)      (None, 64)                54400     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29d213c5250>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "pretrained = keras.Model(functional_model.inputs, functional_model.layers[-1].input, name=\"pretrained_model\")\n",
    "for w in pretrained.weights:\n",
    "    w.assign(tf.random.normal(w.shape))\n",
    "pretrained.save_weights(\"pretrained_ckpt\")\n",
    "print(pretrained.summary())\n",
    "\n",
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(5, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs, outputs=outputs, name=\"new_model\")\n",
    "\n",
    "model.load_weights(\"pretrained_ckpt\")\n",
    "\n",
    "for a, b in zip(pretrained.weights, model.weights):\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())\n",
    "\n",
    "print(\"\\n\", \"-\" * 50)\n",
    "print(model.summary())\n",
    "\n",
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "pretrained_model = keras.Model(inputs=inputs, outputs=x, name=\"pretrained\")\n",
    "\n",
    "model = keras.Sequential([pretrained_model, keras.layers.Dense(5, name=\"predictions\")])\n",
    "print(model.summary())\n",
    "pretrained_model.load_weights(\"pretrained_ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "975eba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29d24b5b9d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dense = functional_model.layers[1]\n",
    "last_dense = functional_model.layers[-1]\n",
    "ckpt_path = tf.train.Checkpoint(dense=first_dense, kernel=last_dense.kernel, bias=last_dense.bias).save(\"ckpt\")\n",
    "\n",
    "class ContrivedModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ContrivedModel, self).__init__()\n",
    "        self.first_dense = keras.layers.Dense(64)\n",
    "        self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
    "        self.bias = self.add_variable(\"bias\", shape=(10,))\n",
    "    def call(self, inputs):\n",
    "        x = self.first_dense(inputs)\n",
    "        return tf.matmul(x, self.kernel) + self.bias\n",
    "\n",
    "model = ContrivedModel()\n",
    "_ = model(tf.ones((1, 784)))\n",
    "tf.train.Checkpoint(dense=model.first_dense, kernel=model.kernel, bias=model.bias).restore(ckpt_path).assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "926e3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_model = keras.Sequential([\n",
    "    keras.Input(shape=(784, ), name=\"digits\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "    keras.layers.Dense(10, name=\"predictions\")\n",
    "])\n",
    "sequential_model.save_weights(\"weights.h5\")\n",
    "sequential_model.load_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c78f57f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varibales: ['nested/dense_1/kernel:0', 'nested/dense_1/bias:0', 'nested/dense_2/kernel:0', 'nested/dense_2/bias:0']\n",
      "\n",
      "Changing trainable status of one of the nested layers...\n",
      "\n",
      "variables: ['nested/dense_2/kernel:0', 'nested/dense_2/bias:0', 'nested/dense_1/kernel:0', 'nested/dense_1/bias:0']\n",
      "variable ordering changed: True\n"
     ]
    }
   ],
   "source": [
    "class NestedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, name=None):\n",
    "        super(NestedDenseLayer, self).__init__(name=name)\n",
    "        self.dense_1 = keras.layers.Dense(units, name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(units, name=\"dense_2\")\n",
    "    def call(self, inputs):\n",
    "        return self.dense_2(self.dense_1(inputs))\n",
    "\n",
    "nested_model = keras.Sequential([keras.Input((784, )), NestedDenseLayer(10, \"nested\")])\n",
    "variable_names = [v.name for v in nested_model.weights]\n",
    "print(\"varibales: {}\".format(variable_names))\n",
    "\n",
    "print(\"\\nChanging trainable status of one of the nested layers...\")\n",
    "nested_model.get_layer(\"nested\").dense_1.trainable=False\n",
    "\n",
    "variables_names_2 = [v.name for v in nested_model.weights]\n",
    "print(\"\\nvariables: {}\".format(variable_names_2))\n",
    "print(\"variable ordering changed:\", variable_names != variables_names_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fd962aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_functional_model():\n",
    "    inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "    return keras.Model(inputs=inputs, outputs = outputs, name=\"3_layer_mlp\")\n",
    "functional_model = create_functional_model()\n",
    "functional_model.save_weights(\"pretrained_weights.h5\")\n",
    "pretrained_model = create_functional_model()\n",
    "pretrained_model.load_weights(\"pretrained_weights.h5\")\n",
    "extracted_layers = pretrained_model.layers[:-1]\n",
    "extracted_layers.append(keras.layers.Dense(5, name=\"dense_3\"))\n",
    "model = keras.Sequential(extracted_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9cd27",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff7944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features mean: -0.00\n",
      "Features std: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7]])\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(data)\n",
    "normalized_data = layer(data)\n",
    "print(\"Features mean: %.2f\"%(normalized_data.numpy().mean()))\n",
    "print(\"Features std: %.2f\"%(normalized_data.numpy().std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390d49c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[23 36 40 31 29  3 35  0  0  0  0]\n",
      " [16 22 10 34 43 28 25  3 41  0  0]\n",
      " [ 5  6  3 15 20 10  4  8  0  0  0]\n",
      " [14  2  7  9  4  8 26 12 42  0  0]\n",
      " [14  2  7  9 13 19  2 39  0  0  0]\n",
      " [18 44  2  5  6  3 15 13  2 17  2]\n",
      " [32 12 33 38  4 11 30 27  0  0  0]\n",
      " [ 5 45 37  3 24  4 11 21  0  0  0]], shape=(8, 11), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"The happend beacause it need to happened\",\n",
    "    \"Why this is heppened as not supposed to be\",\n",
    "    \"i want to ask what is your name\",\n",
    "    \"can you tell me your name please im asking\",\n",
    "    \"can you tell me from where you belong\",\n",
    "    \"Who are you i want to ask from you who's you\",\n",
    "    \"hi im here for your interview its okay\",\n",
    "    \"I am going to take your interview today\"\n",
    "]\n",
    "layer = preprocessing.TextVectorization()\n",
    "layer.adapt(data)\n",
    "vectorized_text = layer(data)\n",
    "print(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832381e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 3 4]\n",
      " [4 0 2]], shape=(2, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
    "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
    "layer = preprocessing.StringLookup(vocabulary=vocab)\n",
    "vectorized_data = layer(data)\n",
    "print(vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16296989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data_augmentation = keras.Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomRotation(0.1),\n",
    "    preprocessing.RandomZoom(0.1)\n",
    "])\n",
    "input_shape = (32, 32, 3)\n",
    "classes = 10\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocessing.Rescaling(1.0 / 255)(x)\n",
    "outputs = keras.applications.ResNet50(weights=None, input_shape=input_shape, classes=classes)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5e59295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 6s 3ms/step - loss: 2.1193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152334a3220>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "input_shape = x_train.shape[1:]\n",
    "classes = 10\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = normalizer(inputs)\n",
    "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5947c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 2 1 0 0 0], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant([\"a\", \"b\", \"c\", \"b\", \"c\", \"a\"])\n",
    "indexer = preprocessing.StringLookup()\n",
    "indexer.adapt(data)\n",
    "# encoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
    "# encoder.adapt(indexer(data))\n",
    "test_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\n",
    "encoded_data = indexer(test_data)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3754c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2 1 0 0 4], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant([10, 20, 20, 10, 30, 0])\n",
    "indexer = preprocessing.IntegerLookup()\n",
    "indexer.adapt(data)\n",
    "test_data = tf.constant([10, 10, 20, 50, 60, 0])\n",
    "encoded_data = indexer(test_data)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7c482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
      "(10000, 64)\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 100000, size=(10000, 1))\n",
    "hasher = preprocessing.Hashing(num_bins=64, salt=1337)\n",
    "encoder = preprocessing.CategoryEncoding(max_tokens=64, output_mode=\"binary\")\n",
    "encoded_data = encoder(hasher(data))\n",
    "print(encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56fbf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['', '[UNK]', 'the', 'side', 'you', 'with', 'will', 'wider', 'them', 'than', 'sky', 'put', 'other', 'one', 'is', 'for', 'ease', 'contain', 'by', 'brain', 'beside', 'and']\n",
      "tf.Tensor([[0.00528428]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant([\n",
    "    \"The Brain is wider than the sky\",\n",
    "    \"For put them side by side\",\n",
    "    \"The one the other will contain\",\n",
    "    \"With ease and You beside\",\n",
    "])\n",
    "text_vectorizer = preprocessing.TextVectorization(output_mode=\"int\")\n",
    "text_vectorizer.adapt(data)\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "print(\"Vocabulary:\", vocab)\n",
    "inputs = keras.Input(shape=(1, ), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = layers.Embedding(input_dim=len(vocab), output_dim=64)(x)\n",
    "outputs = layers.LSTM(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "test_data = tf.constant([\"The Brain is Deeper than the sea\"])\n",
    "test_output = model(test_data)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "609a2509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding text:\n",
      " [[5.461647  1.6945957 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        1.0986123 1.0986123 1.0986123 0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  1.0986123 0.        0.        0.        0.        0.        0.\n",
      "  0.        1.0986123 1.0986123 0.        0.        0.       ]]\n",
      "Model output: tf.Tensor([[0.7962239]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant([\n",
    "    \"The Brain is wider than the sky\",\n",
    "    \"For put them side by side\",\n",
    "    \"The one the other will contain\",\n",
    "    \"With ease and You beside\",\n",
    "])\n",
    "text_vectorizer = preprocessing.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\n",
    "text_vectorizer.adapt(data)\n",
    "print(\"Encoding text:\\n\", text_vectorizer([\"The Brain is deeper than the sea\"]).numpy())\n",
    "inputs = keras.Input(shape=(1, ), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
    "test_output = model(test_data)\n",
    "print(\"Model output:\", test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230cbb3",
   "metadata": {},
   "source": [
    "# Customize What happens in Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48330aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f5765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e471eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.2161 - mae: 0.3769\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2032 - mae: 0.3657\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1919 - mae: 0.3552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272d5d744f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8617ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6215 - mae: 0.6753\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.4161\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2017 - mae: 0.3686\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1974 - mae: 0.3642\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1939 - mae: 0.3609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272d6e23490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = keras.losses.mean_squared_error(y, y_pred)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        loss_tracker.update_state(loss)\n",
    "        mae_metric.update_state(y, y_pred)\n",
    "        return {\"loss\": loss_tracker.result(), \"mae\":mae_metric.result()}\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker, mae_metric]\n",
    "inputs = keras.Input(shape=(32, ))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\")\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287fce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.1862 - mae: 0.5040\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1126 - mae: 0.3941\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1083 - mae: 0.3864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272d718cc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, sample_weight = sample_weight, regularization_losses = self.losses)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "sw = np.random.random((1000, 1))\n",
    "model.fit(x, y, sample_weight=sw, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfc91fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5690 - mae: 0.6309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5689986348152161, 0.6309337019920349]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "inputs = keras.Input(shape=(32, ))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(loss=\"mse\", metrics=[\"mae\"])\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ede7df",
   "metadata": {},
   "source": [
    "# Writting a training loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6711d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05a082d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784, ), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35ec106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "batch_size=64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5906e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sart of epoch 0\n",
      "Training oss (for one batch) at step 0: 93.3372\n",
      "Seen so far: 64 sample\n",
      "Training oss (for one batch) at step 200: 1.6175\n",
      "Seen so far: 12864 sample\n",
      "Training oss (for one batch) at step 400: 0.9404\n",
      "Seen so far: 25664 sample\n",
      "Training oss (for one batch) at step 600: 0.7993\n",
      "Seen so far: 38464 sample\n",
      "\n",
      "Sart of epoch 1\n",
      "Training oss (for one batch) at step 0: 0.9840\n",
      "Seen so far: 64 sample\n",
      "Training oss (for one batch) at step 200: 0.8632\n",
      "Seen so far: 12864 sample\n",
      "Training oss (for one batch) at step 400: 1.2538\n",
      "Seen so far: 25664 sample\n",
      "Training oss (for one batch) at step 600: 0.7111\n",
      "Seen so far: 38464 sample\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nSart of epoch %d\"%(epoch))\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        if step % 200 == 0:\n",
    "            print(\"Training oss (for one batch) at step %d: %.4f\"%(step, float(loss_value)))\n",
    "            print(\"Seen so far: %s sample\"%((step + 1) * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e67680d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b34ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc8578f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33e41729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.3795\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8033\n",
      "Time taken: 0.42\n",
      "Training acc over epoch: 0.703125\n",
      "Validation acc: 0.8565\n",
      "Time taken: 0.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8579\n",
      "Time taken: 0.71\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8576\n",
      "Time taken: 0.85\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8555\n",
      "Time taken: 0.99\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8569\n",
      "Time taken: 1.13\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8570\n",
      "Time taken: 1.34\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8569\n",
      "Time taken: 1.54\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8584\n",
      "Time taken: 1.67\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8590\n",
      "Time taken: 1.81\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8553\n",
      "Time taken: 1.92\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8572\n",
      "Time taken: 2.06\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8566\n",
      "Time taken: 2.17\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8563\n",
      "Time taken: 2.37\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8561\n",
      "Time taken: 2.54\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8544\n",
      "Time taken: 2.68\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8528\n",
      "Time taken: 2.81\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8538\n",
      "Time taken: 2.95\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8546\n",
      "Time taken: 3.11\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8555\n",
      "Time taken: 3.27\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8479\n",
      "Time taken: 3.39\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8486\n",
      "Time taken: 3.53\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8559\n",
      "Time taken: 3.67\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8569\n",
      "Time taken: 3.84\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8547\n",
      "Time taken: 3.98\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8509\n",
      "Time taken: 4.11\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8538\n",
      "Time taken: 4.24\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8449\n",
      "Time taken: 4.42\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8548\n",
      "Time taken: 4.59\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8561\n",
      "Time taken: 4.73\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8558\n",
      "Time taken: 4.85\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8557\n",
      "Time taken: 5.04\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8561\n",
      "Time taken: 5.23\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8547\n",
      "Time taken: 5.34\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8547\n",
      "Time taken: 5.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8573\n",
      "Time taken: 5.59\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8518\n",
      "Time taken: 5.73\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8555\n",
      "Time taken: 5.85\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8540\n",
      "Time taken: 5.98\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8512\n",
      "Time taken: 6.09\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8512\n",
      "Time taken: 6.23\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8511\n",
      "Time taken: 6.34\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8533\n",
      "Time taken: 6.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8525\n",
      "Time taken: 6.60\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8538\n",
      "Time taken: 6.74\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8515\n",
      "Time taken: 6.84\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8459\n",
      "Time taken: 6.99\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8507\n",
      "Time taken: 7.13\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8503\n",
      "Time taken: 7.27\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8527\n",
      "Time taken: 7.38\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8539\n",
      "Time taken: 7.51\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8492\n",
      "Time taken: 7.66\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8525\n",
      "Time taken: 7.81\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8498\n",
      "Time taken: 7.93\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8524\n",
      "Time taken: 8.06\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8507\n",
      "Time taken: 8.17\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8490\n",
      "Time taken: 8.30\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8514\n",
      "Time taken: 8.41\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8498\n",
      "Time taken: 8.53\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8518\n",
      "Time taken: 8.66\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8502\n",
      "Time taken: 8.78\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8514\n",
      "Time taken: 8.93\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8506\n",
      "Time taken: 9.06\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8513\n",
      "Time taken: 9.18\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8545\n",
      "Time taken: 9.31\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8556\n",
      "Time taken: 9.43\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8510\n",
      "Time taken: 9.57\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8450\n",
      "Time taken: 9.69\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8545\n",
      "Time taken: 9.84\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8523\n",
      "Time taken: 9.97\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8548\n",
      "Time taken: 10.10\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8545\n",
      "Time taken: 10.22\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8532\n",
      "Time taken: 10.39\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8538\n",
      "Time taken: 10.56\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8542\n",
      "Time taken: 10.68\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8545\n",
      "Time taken: 10.81\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8535\n",
      "Time taken: 10.93\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8553\n",
      "Time taken: 11.07\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8548\n",
      "Time taken: 11.17\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8559\n",
      "Time taken: 11.28\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8546\n",
      "Time taken: 11.41\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8510\n",
      "Time taken: 11.52\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8548\n",
      "Time taken: 11.64\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8555\n",
      "Time taken: 11.77\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8525\n",
      "Time taken: 11.89\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8537\n",
      "Time taken: 12.02\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8507\n",
      "Time taken: 12.12\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8523\n",
      "Time taken: 12.25\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8527\n",
      "Time taken: 12.37\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8492\n",
      "Time taken: 12.51\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8550\n",
      "Time taken: 12.62\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8564\n",
      "Time taken: 12.76\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8562\n",
      "Time taken: 12.88\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8556\n",
      "Time taken: 13.03\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8558\n",
      "Time taken: 13.15\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8573\n",
      "Time taken: 13.28\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8570\n",
      "Time taken: 13.40\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8569\n",
      "Time taken: 13.53\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8570\n",
      "Time taken: 13.64\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8445\n",
      "Time taken: 13.77\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8443\n",
      "Time taken: 13.89\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8458\n",
      "Time taken: 14.03\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8479\n",
      "Time taken: 14.14\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8510\n",
      "Time taken: 14.28\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8491\n",
      "Time taken: 14.40\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8492\n",
      "Time taken: 14.53\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8543\n",
      "Time taken: 14.64\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8281\n",
      "Time taken: 14.77\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8275\n",
      "Time taken: 14.89\n",
      "Training acc over epoch: 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8484\n",
      "Time taken: 15.04\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8511\n",
      "Time taken: 15.15\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8535\n",
      "Time taken: 15.29\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8568\n",
      "Time taken: 15.41\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8584\n",
      "Time taken: 15.55\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8578\n",
      "Time taken: 15.72\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8569\n",
      "Time taken: 15.91\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8560\n",
      "Time taken: 16.02\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8585\n",
      "Time taken: 16.11\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8586\n",
      "Time taken: 16.24\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8590\n",
      "Time taken: 16.36\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8574\n",
      "Time taken: 16.47\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8567\n",
      "Time taken: 16.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8591\n",
      "Time taken: 16.77\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8564\n",
      "Time taken: 16.91\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8529\n",
      "Time taken: 17.05\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8568\n",
      "Time taken: 17.19\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8568\n",
      "Time taken: 17.32\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8516\n",
      "Time taken: 17.46\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8478\n",
      "Time taken: 17.61\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8523\n",
      "Time taken: 17.73\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8378\n",
      "Time taken: 17.84\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8521\n",
      "Time taken: 17.97\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8487\n",
      "Time taken: 18.09\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8542\n",
      "Time taken: 18.23\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8551\n",
      "Time taken: 18.34\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8546\n",
      "Time taken: 18.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8553\n",
      "Time taken: 18.60\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8559\n",
      "Time taken: 18.74\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8547\n",
      "Time taken: 18.85\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8568\n",
      "Time taken: 19.00\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8505\n",
      "Time taken: 19.12\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8561\n",
      "Time taken: 19.26\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8550\n",
      "Time taken: 19.37\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8571\n",
      "Time taken: 19.51\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8577\n",
      "Time taken: 19.64\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8593\n",
      "Time taken: 19.77\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8542\n",
      "Time taken: 19.89\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8559\n",
      "Time taken: 20.03\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8585\n",
      "Time taken: 20.14\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8605\n",
      "Time taken: 20.28\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8602\n",
      "Time taken: 20.40\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8588\n",
      "Time taken: 20.54\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8593\n",
      "Time taken: 20.65\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8569\n",
      "Time taken: 20.78\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8595\n",
      "Time taken: 20.89\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8593\n",
      "Time taken: 21.09\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8595\n",
      "Time taken: 21.26\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8600\n",
      "Time taken: 21.38\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8614\n",
      "Time taken: 21.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8610\n",
      "Time taken: 21.60\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8610\n",
      "Time taken: 21.71\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8600\n",
      "Time taken: 21.84\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8585\n",
      "Time taken: 21.95\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8627\n",
      "Time taken: 22.09\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8629\n",
      "Time taken: 22.20\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8631\n",
      "Time taken: 22.34\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8633\n",
      "Time taken: 22.46\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8638\n",
      "Time taken: 22.59\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8611\n",
      "Time taken: 22.70\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8610\n",
      "Time taken: 22.83\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8606\n",
      "Time taken: 22.94\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8589\n",
      "Time taken: 23.09\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8597\n",
      "Time taken: 23.20\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8600\n",
      "Time taken: 23.34\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8611\n",
      "Time taken: 23.46\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8615\n",
      "Time taken: 23.59\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8600\n",
      "Time taken: 23.71\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8610\n",
      "Time taken: 23.84\n",
      "Training acc over epoch: 0.718750\n",
      "Validation acc: 0.8538\n",
      "Time taken: 23.97\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8565\n",
      "Time taken: 24.10\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8602\n",
      "Time taken: 24.22\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8595\n",
      "Time taken: 24.35\n",
      "Training acc over epoch: 0.984375\n",
      "Validation acc: 0.8605\n",
      "Time taken: 24.47\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8610\n",
      "Time taken: 24.60\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8605\n",
      "Time taken: 24.71\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8621\n",
      "Time taken: 24.84\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8622\n",
      "Time taken: 24.96\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8620\n",
      "Time taken: 25.09\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8579\n",
      "Time taken: 25.22\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8597\n",
      "Time taken: 25.36\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8604\n",
      "Time taken: 25.49\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8618\n",
      "Time taken: 25.62\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8560\n",
      "Time taken: 25.74\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8573\n",
      "Time taken: 25.87\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8566\n",
      "Time taken: 25.99\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8599\n",
      "Time taken: 26.12\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8569\n",
      "Time taken: 26.24\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8602\n",
      "Time taken: 26.42\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8544\n",
      "Time taken: 26.60\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8582\n",
      "Time taken: 26.71\n",
      "Training loss (for one batch) at step 200: 0.5200\n",
      "Seen so far: 12864 samples\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8583\n",
      "Time taken: 26.82\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8613\n",
      "Time taken: 26.97\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8533\n",
      "Time taken: 27.07\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8498\n",
      "Time taken: 27.21\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8572\n",
      "Time taken: 27.34\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8570\n",
      "Time taken: 27.48\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8548\n",
      "Time taken: 27.59\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8568\n",
      "Time taken: 27.73\n",
      "Training acc over epoch: 0.718750\n",
      "Validation acc: 0.8290\n",
      "Time taken: 27.85\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8546\n",
      "Time taken: 27.99\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8522\n",
      "Time taken: 28.12\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8316\n",
      "Time taken: 28.26\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8542\n",
      "Time taken: 28.39\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8547\n",
      "Time taken: 28.52\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8556\n",
      "Time taken: 28.64\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8551\n",
      "Time taken: 28.78\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8599\n",
      "Time taken: 28.90\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8608\n",
      "Time taken: 29.04\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8613\n",
      "Time taken: 29.17\n",
      "Training acc over epoch: 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8599\n",
      "Time taken: 29.31\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8598\n",
      "Time taken: 29.44\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8583\n",
      "Time taken: 29.58\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8588\n",
      "Time taken: 29.70\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8589\n",
      "Time taken: 29.84\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8545\n",
      "Time taken: 29.95\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8562\n",
      "Time taken: 30.09\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8590\n",
      "Time taken: 30.20\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8585\n",
      "Time taken: 30.35\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8589\n",
      "Time taken: 30.47\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8590\n",
      "Time taken: 30.61\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8568\n",
      "Time taken: 30.72\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8504\n",
      "Time taken: 30.86\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8549\n",
      "Time taken: 30.99\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8572\n",
      "Time taken: 31.13\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8574\n",
      "Time taken: 31.25\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8583\n",
      "Time taken: 31.39\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8578\n",
      "Time taken: 31.50\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8585\n",
      "Time taken: 31.68\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8611\n",
      "Time taken: 31.86\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8607\n",
      "Time taken: 31.99\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8596\n",
      "Time taken: 32.11\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8568\n",
      "Time taken: 32.22\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8583\n",
      "Time taken: 32.35\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8566\n",
      "Time taken: 32.47\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8546\n",
      "Time taken: 32.61\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8555\n",
      "Time taken: 32.74\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8523\n",
      "Time taken: 32.88\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8617\n",
      "Time taken: 33.01\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8609\n",
      "Time taken: 33.16\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8620\n",
      "Time taken: 33.28\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8552\n",
      "Time taken: 33.43\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8557\n",
      "Time taken: 33.56\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8546\n",
      "Time taken: 33.69\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8558\n",
      "Time taken: 33.80\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8556\n",
      "Time taken: 33.93\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8592\n",
      "Time taken: 34.05\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8620\n",
      "Time taken: 34.19\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8632\n",
      "Time taken: 34.33\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8634\n",
      "Time taken: 34.46\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8619\n",
      "Time taken: 34.59\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8621\n",
      "Time taken: 34.73\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8625\n",
      "Time taken: 34.88\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8637\n",
      "Time taken: 35.04\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8651\n",
      "Time taken: 35.19\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8637\n",
      "Time taken: 35.34\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8608\n",
      "Time taken: 35.49\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8584\n",
      "Time taken: 35.63\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8648\n",
      "Time taken: 35.78\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8622\n",
      "Time taken: 35.92\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8602\n",
      "Time taken: 36.08\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8639\n",
      "Time taken: 36.23\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8617\n",
      "Time taken: 36.37\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8625\n",
      "Time taken: 36.52\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8621\n",
      "Time taken: 36.68\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8587\n",
      "Time taken: 36.83\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8584\n",
      "Time taken: 37.04\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8628\n",
      "Time taken: 37.30\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8630\n",
      "Time taken: 37.43\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8648\n",
      "Time taken: 37.55\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8662\n",
      "Time taken: 37.66\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8637\n",
      "Time taken: 37.79\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8631\n",
      "Time taken: 37.92\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8609\n",
      "Time taken: 38.06\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8618\n",
      "Time taken: 38.17\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8624\n",
      "Time taken: 38.32\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8627\n",
      "Time taken: 38.44\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8619\n",
      "Time taken: 38.58\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8617\n",
      "Time taken: 38.70\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8622\n",
      "Time taken: 38.84\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8625\n",
      "Time taken: 38.96\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8621\n",
      "Time taken: 39.09\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8610\n",
      "Time taken: 39.22\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8633\n",
      "Time taken: 39.36\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8634\n",
      "Time taken: 39.47\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8636\n",
      "Time taken: 39.61\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8611\n",
      "Time taken: 39.74\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8567\n",
      "Time taken: 39.87\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8589\n",
      "Time taken: 39.99\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8593\n",
      "Time taken: 40.13\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8577\n",
      "Time taken: 40.25\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8627\n",
      "Time taken: 40.39\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8687\n",
      "Time taken: 40.51\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8657\n",
      "Time taken: 40.64\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8644\n",
      "Time taken: 40.75\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8652\n",
      "Time taken: 40.90\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8641\n",
      "Time taken: 41.02\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8647\n",
      "Time taken: 41.16\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8642\n",
      "Time taken: 41.29\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8609\n",
      "Time taken: 41.42\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8590\n",
      "Time taken: 41.54\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8577\n",
      "Time taken: 41.68\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8595\n",
      "Time taken: 41.79\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8601\n",
      "Time taken: 41.93\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8614\n",
      "Time taken: 42.06\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8634\n",
      "Time taken: 42.19\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8596\n",
      "Time taken: 42.32\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8621\n",
      "Time taken: 42.53\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8617\n",
      "Time taken: 42.67\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8656\n",
      "Time taken: 42.79\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8648\n",
      "Time taken: 42.90\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8613\n",
      "Time taken: 43.05\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8619\n",
      "Time taken: 43.17\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8626\n",
      "Time taken: 43.31\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8596\n",
      "Time taken: 43.42\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8641\n",
      "Time taken: 43.56\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8608\n",
      "Time taken: 43.69\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8614\n",
      "Time taken: 43.82\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8614\n",
      "Time taken: 43.95\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8589\n",
      "Time taken: 44.08\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8598\n",
      "Time taken: 44.21\n",
      "Training acc over epoch: 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8572\n",
      "Time taken: 44.34\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8554\n",
      "Time taken: 44.45\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8565\n",
      "Time taken: 44.59\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8568\n",
      "Time taken: 44.72\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8583\n",
      "Time taken: 44.86\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8585\n",
      "Time taken: 44.97\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8615\n",
      "Time taken: 45.11\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8569\n",
      "Time taken: 45.23\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8540\n",
      "Time taken: 45.36\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8553\n",
      "Time taken: 45.47\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8583\n",
      "Time taken: 45.61\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8590\n",
      "Time taken: 45.74\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8577\n",
      "Time taken: 45.87\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8565\n",
      "Time taken: 45.99\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8582\n",
      "Time taken: 46.13\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8599\n",
      "Time taken: 46.26\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8565\n",
      "Time taken: 46.39\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8547\n",
      "Time taken: 46.50\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8563\n",
      "Time taken: 46.64\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8617\n",
      "Time taken: 46.77\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8623\n",
      "Time taken: 46.90\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8623\n",
      "Time taken: 47.02\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8638\n",
      "Time taken: 47.16\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8630\n",
      "Time taken: 47.27\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8620\n",
      "Time taken: 47.40\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8628\n",
      "Time taken: 47.52\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8672\n",
      "Time taken: 47.68\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8649\n",
      "Time taken: 47.88\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8631\n",
      "Time taken: 48.02\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8660\n",
      "Time taken: 48.15\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8668\n",
      "Time taken: 48.25\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8662\n",
      "Time taken: 48.38\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8662\n",
      "Time taken: 48.49\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8614\n",
      "Time taken: 48.64\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8610\n",
      "Time taken: 48.77\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8578\n",
      "Time taken: 48.91\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8667\n",
      "Time taken: 49.05\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8606\n",
      "Time taken: 49.19\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8621\n",
      "Time taken: 49.33\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8589\n",
      "Time taken: 49.48\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8597\n",
      "Time taken: 49.62\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8613\n",
      "Time taken: 49.74\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8603\n",
      "Time taken: 49.86\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8624\n",
      "Time taken: 50.01\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8615\n",
      "Time taken: 50.16\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8638\n",
      "Time taken: 50.30\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8627\n",
      "Time taken: 50.45\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8613\n",
      "Time taken: 50.60\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8622\n",
      "Time taken: 50.74\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8649\n",
      "Time taken: 50.89\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8633\n",
      "Time taken: 51.04\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8665\n",
      "Time taken: 51.19\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8651\n",
      "Time taken: 51.33\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8649\n",
      "Time taken: 51.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8651\n",
      "Time taken: 51.62\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8680\n",
      "Time taken: 51.77\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8672\n",
      "Time taken: 51.89\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8616\n",
      "Time taken: 52.03\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8678\n",
      "Time taken: 52.14\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8642\n",
      "Time taken: 52.28\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8684\n",
      "Time taken: 52.39\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8661\n",
      "Time taken: 52.53\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8696\n",
      "Time taken: 52.66\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8672\n",
      "Time taken: 52.78\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8670\n",
      "Time taken: 52.92\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8658\n",
      "Time taken: 53.11\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8649\n",
      "Time taken: 53.29\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8628\n",
      "Time taken: 53.41\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8600\n",
      "Time taken: 53.53\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8631\n",
      "Time taken: 53.66\n",
      "Training loss (for one batch) at step 400: 0.6556\n",
      "Seen so far: 25664 samples\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8593\n",
      "Time taken: 53.78\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8657\n",
      "Time taken: 53.90\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8668\n",
      "Time taken: 54.03\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8651\n",
      "Time taken: 54.14\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8584\n",
      "Time taken: 54.28\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8664\n",
      "Time taken: 54.39\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8663\n",
      "Time taken: 54.52\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8603\n",
      "Time taken: 54.64\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8657\n",
      "Time taken: 54.77\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8660\n",
      "Time taken: 54.89\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8567\n",
      "Time taken: 55.02\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8613\n",
      "Time taken: 55.14\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8647\n",
      "Time taken: 55.28\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8676\n",
      "Time taken: 55.40\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8672\n",
      "Time taken: 55.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8612\n",
      "Time taken: 55.69\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8636\n",
      "Time taken: 55.82\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8681\n",
      "Time taken: 55.94\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8634\n",
      "Time taken: 56.07\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8613\n",
      "Time taken: 56.19\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8567\n",
      "Time taken: 56.33\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8577\n",
      "Time taken: 56.44\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8628\n",
      "Time taken: 56.57\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8577\n",
      "Time taken: 56.69\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8643\n",
      "Time taken: 56.82\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8630\n",
      "Time taken: 56.92\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8656\n",
      "Time taken: 57.07\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8668\n",
      "Time taken: 57.19\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8656\n",
      "Time taken: 57.32\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8642\n",
      "Time taken: 57.44\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8676\n",
      "Time taken: 57.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8665\n",
      "Time taken: 57.67\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8540\n",
      "Time taken: 57.81\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8615\n",
      "Time taken: 57.93\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8658\n",
      "Time taken: 58.06\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8614\n",
      "Time taken: 58.19\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8618\n",
      "Time taken: 58.34\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8647\n",
      "Time taken: 58.52\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8655\n",
      "Time taken: 58.67\n",
      "Training acc over epoch: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8640\n",
      "Time taken: 58.79\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8652\n",
      "Time taken: 58.92\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8666\n",
      "Time taken: 59.05\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8649\n",
      "Time taken: 59.17\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8671\n",
      "Time taken: 59.30\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8696\n",
      "Time taken: 59.41\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8609\n",
      "Time taken: 59.55\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8658\n",
      "Time taken: 59.66\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8598\n",
      "Time taken: 59.79\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8696\n",
      "Time taken: 59.91\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8676\n",
      "Time taken: 60.05\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8704\n",
      "Time taken: 60.17\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8662\n",
      "Time taken: 60.30\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8668\n",
      "Time taken: 60.42\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8615\n",
      "Time taken: 60.56\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8619\n",
      "Time taken: 60.69\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8673\n",
      "Time taken: 60.82\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8691\n",
      "Time taken: 60.94\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8690\n",
      "Time taken: 61.08\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8706\n",
      "Time taken: 61.20\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8699\n",
      "Time taken: 61.34\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8713\n",
      "Time taken: 61.45\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8677\n",
      "Time taken: 61.59\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8691\n",
      "Time taken: 61.71\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8696\n",
      "Time taken: 61.84\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8691\n",
      "Time taken: 61.95\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8674\n",
      "Time taken: 62.08\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8669\n",
      "Time taken: 62.19\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8684\n",
      "Time taken: 62.34\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8665\n",
      "Time taken: 62.45\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8668\n",
      "Time taken: 62.59\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8674\n",
      "Time taken: 62.71\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8671\n",
      "Time taken: 62.85\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8679\n",
      "Time taken: 62.97\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8616\n",
      "Time taken: 63.11\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8658\n",
      "Time taken: 63.24\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8617\n",
      "Time taken: 63.38\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8583\n",
      "Time taken: 63.49\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8615\n",
      "Time taken: 63.65\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8654\n",
      "Time taken: 63.84\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8630\n",
      "Time taken: 63.99\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8628\n",
      "Time taken: 64.11\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8636\n",
      "Time taken: 64.24\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8674\n",
      "Time taken: 64.37\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8683\n",
      "Time taken: 64.49\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8667\n",
      "Time taken: 64.63\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8667\n",
      "Time taken: 64.77\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8664\n",
      "Time taken: 64.91\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8644\n",
      "Time taken: 65.05\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8658\n",
      "Time taken: 65.19\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8648\n",
      "Time taken: 65.34\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8693\n",
      "Time taken: 65.49\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8669\n",
      "Time taken: 65.62\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8665\n",
      "Time taken: 65.76\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8630\n",
      "Time taken: 65.89\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8685\n",
      "Time taken: 66.01\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8656\n",
      "Time taken: 66.15\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8631\n",
      "Time taken: 66.28\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8666\n",
      "Time taken: 66.41\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8654\n",
      "Time taken: 66.55\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8664\n",
      "Time taken: 66.67\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8664\n",
      "Time taken: 66.81\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8671\n",
      "Time taken: 66.94\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8709\n",
      "Time taken: 67.07\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8703\n",
      "Time taken: 67.19\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8678\n",
      "Time taken: 67.32\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8702\n",
      "Time taken: 67.45\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8725\n",
      "Time taken: 67.57\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8707\n",
      "Time taken: 67.69\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8683\n",
      "Time taken: 67.83\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8652\n",
      "Time taken: 67.94\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8702\n",
      "Time taken: 68.09\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8713\n",
      "Time taken: 68.20\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8700\n",
      "Time taken: 68.34\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8723\n",
      "Time taken: 68.45\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8692\n",
      "Time taken: 68.60\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8738\n",
      "Time taken: 68.72\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8743\n",
      "Time taken: 68.85\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8734\n",
      "Time taken: 69.00\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8722\n",
      "Time taken: 69.19\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8736\n",
      "Time taken: 69.33\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8724\n",
      "Time taken: 69.44\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8724\n",
      "Time taken: 69.58\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8734\n",
      "Time taken: 69.71\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8737\n",
      "Time taken: 69.84\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8727\n",
      "Time taken: 69.98\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8710\n",
      "Time taken: 70.10\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8735\n",
      "Time taken: 70.23\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8745\n",
      "Time taken: 70.36\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8756\n",
      "Time taken: 70.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8724\n",
      "Time taken: 70.61\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8726\n",
      "Time taken: 70.73\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8709\n",
      "Time taken: 70.85\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8709\n",
      "Time taken: 71.00\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8676\n",
      "Time taken: 71.12\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8687\n",
      "Time taken: 71.25\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8738\n",
      "Time taken: 71.37\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8720\n",
      "Time taken: 71.51\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8694\n",
      "Time taken: 71.62\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8724\n",
      "Time taken: 71.75\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8691\n",
      "Time taken: 71.87\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8715\n",
      "Time taken: 72.00\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8733\n",
      "Time taken: 72.12\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8738\n",
      "Time taken: 72.25\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8745\n",
      "Time taken: 72.37\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8671\n",
      "Time taken: 72.51\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8680\n",
      "Time taken: 72.62\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8693\n",
      "Time taken: 72.76\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8645\n",
      "Time taken: 72.89\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8638\n",
      "Time taken: 73.02\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8683\n",
      "Time taken: 73.15\n",
      "Training acc over epoch: 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8687\n",
      "Time taken: 73.29\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8647\n",
      "Time taken: 73.42\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8691\n",
      "Time taken: 73.55\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8694\n",
      "Time taken: 73.67\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8717\n",
      "Time taken: 73.81\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8625\n",
      "Time taken: 73.92\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8684\n",
      "Time taken: 74.07\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8668\n",
      "Time taken: 74.19\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8688\n",
      "Time taken: 74.35\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8573\n",
      "Time taken: 74.53\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8691\n",
      "Time taken: 74.67\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8726\n",
      "Time taken: 74.79\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8737\n",
      "Time taken: 74.91\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8703\n",
      "Time taken: 75.03\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8680\n",
      "Time taken: 75.16\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8693\n",
      "Time taken: 75.30\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8725\n",
      "Time taken: 75.41\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8696\n",
      "Time taken: 75.55\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8730\n",
      "Time taken: 75.67\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8712\n",
      "Time taken: 75.81\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8717\n",
      "Time taken: 75.94\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8718\n",
      "Time taken: 76.06\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8733\n",
      "Time taken: 76.19\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8735\n",
      "Time taken: 76.33\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8721\n",
      "Time taken: 76.45\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8743\n",
      "Time taken: 76.58\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8728\n",
      "Time taken: 76.70\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8741\n",
      "Time taken: 76.84\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8713\n",
      "Time taken: 76.95\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8727\n",
      "Time taken: 77.09\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8716\n",
      "Time taken: 77.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8702\n",
      "Time taken: 77.34\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8686\n",
      "Time taken: 77.46\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8689\n",
      "Time taken: 77.61\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8677\n",
      "Time taken: 77.76\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8667\n",
      "Time taken: 77.91\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8647\n",
      "Time taken: 78.06\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8679\n",
      "Time taken: 78.21\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8656\n",
      "Time taken: 78.36\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8679\n",
      "Time taken: 78.51\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8720\n",
      "Time taken: 78.65\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8709\n",
      "Time taken: 78.81\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8733\n",
      "Time taken: 78.96\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8726\n",
      "Time taken: 79.12\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8733\n",
      "Time taken: 79.26\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8713\n",
      "Time taken: 79.41\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8722\n",
      "Time taken: 79.56\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8718\n",
      "Time taken: 79.78\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8700\n",
      "Time taken: 80.03\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8688\n",
      "Time taken: 80.15\n",
      "Training loss (for one batch) at step 600: 0.6291\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8629\n",
      "Time taken: 80.29\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8720\n",
      "Time taken: 80.42\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8736\n",
      "Time taken: 80.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8696\n",
      "Time taken: 80.73\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8694\n",
      "Time taken: 80.88\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8698\n",
      "Time taken: 81.02\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8698\n",
      "Time taken: 81.16\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8656\n",
      "Time taken: 81.31\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8671\n",
      "Time taken: 81.44\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8696\n",
      "Time taken: 81.58\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8628\n",
      "Time taken: 81.71\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8706\n",
      "Time taken: 81.84\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8644\n",
      "Time taken: 81.97\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8695\n",
      "Time taken: 82.07\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8707\n",
      "Time taken: 82.21\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8712\n",
      "Time taken: 82.33\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8696\n",
      "Time taken: 82.47\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8674\n",
      "Time taken: 82.57\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8663\n",
      "Time taken: 82.71\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8690\n",
      "Time taken: 82.83\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8687\n",
      "Time taken: 82.96\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8654\n",
      "Time taken: 83.07\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8690\n",
      "Time taken: 83.22\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8652\n",
      "Time taken: 83.35\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8648\n",
      "Time taken: 83.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8684\n",
      "Time taken: 83.60\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8732\n",
      "Time taken: 83.74\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8739\n",
      "Time taken: 83.87\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8707\n",
      "Time taken: 84.00\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8707\n",
      "Time taken: 84.12\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8713\n",
      "Time taken: 84.27\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8713\n",
      "Time taken: 84.39\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8699\n",
      "Time taken: 84.53\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8719\n",
      "Time taken: 84.64\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8681\n",
      "Time taken: 84.77\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8727\n",
      "Time taken: 84.89\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8736\n",
      "Time taken: 85.05\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8711\n",
      "Time taken: 85.23\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8691\n",
      "Time taken: 85.39\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8709\n",
      "Time taken: 85.51\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8733\n",
      "Time taken: 85.63\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8738\n",
      "Time taken: 85.75\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8741\n",
      "Time taken: 85.89\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8707\n",
      "Time taken: 86.02\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8741\n",
      "Time taken: 86.14\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8754\n",
      "Time taken: 86.27\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8751\n",
      "Time taken: 86.41\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8749\n",
      "Time taken: 86.54\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8741\n",
      "Time taken: 86.68\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8737\n",
      "Time taken: 86.80\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8728\n",
      "Time taken: 86.94\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8722\n",
      "Time taken: 87.07\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8746\n",
      "Time taken: 87.21\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8737\n",
      "Time taken: 87.34\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8734\n",
      "Time taken: 87.46\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8731\n",
      "Time taken: 87.59\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8736\n",
      "Time taken: 87.71\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8769\n",
      "Time taken: 87.82\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8739\n",
      "Time taken: 87.96\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8745\n",
      "Time taken: 88.07\n",
      "Training acc over epoch: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8772\n",
      "Time taken: 88.21\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8764\n",
      "Time taken: 88.32\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8771\n",
      "Time taken: 88.46\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8777\n",
      "Time taken: 88.57\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8740\n",
      "Time taken: 88.70\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8753\n",
      "Time taken: 88.81\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8754\n",
      "Time taken: 88.93\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8769\n",
      "Time taken: 89.04\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8766\n",
      "Time taken: 89.16\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8739\n",
      "Time taken: 89.29\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8721\n",
      "Time taken: 89.42\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8755\n",
      "Time taken: 89.54\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8743\n",
      "Time taken: 89.68\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8758\n",
      "Time taken: 89.79\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8759\n",
      "Time taken: 89.92\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8721\n",
      "Time taken: 90.04\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8746\n",
      "Time taken: 90.16\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8746\n",
      "Time taken: 90.28\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8728\n",
      "Time taken: 90.43\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8725\n",
      "Time taken: 90.60\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8730\n",
      "Time taken: 90.76\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8732\n",
      "Time taken: 90.86\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8734\n",
      "Time taken: 91.00\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8748\n",
      "Time taken: 91.11\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8747\n",
      "Time taken: 91.25\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8752\n",
      "Time taken: 91.36\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8754\n",
      "Time taken: 91.50\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8755\n",
      "Time taken: 91.62\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8756\n",
      "Time taken: 91.75\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8757\n",
      "Time taken: 91.86\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8720\n",
      "Time taken: 91.98\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8720\n",
      "Time taken: 92.09\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8733\n",
      "Time taken: 92.22\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8732\n",
      "Time taken: 92.34\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8738\n",
      "Time taken: 92.47\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8738\n",
      "Time taken: 92.59\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8705\n",
      "Time taken: 92.72\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8744\n",
      "Time taken: 92.84\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8744\n",
      "Time taken: 92.98\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8741\n",
      "Time taken: 93.09\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8699\n",
      "Time taken: 93.23\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8706\n",
      "Time taken: 93.34\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8692\n",
      "Time taken: 93.47\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8719\n",
      "Time taken: 93.57\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8714\n",
      "Time taken: 93.71\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8668\n",
      "Time taken: 93.82\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8713\n",
      "Time taken: 93.96\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8708\n",
      "Time taken: 94.07\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8718\n",
      "Time taken: 94.21\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8710\n",
      "Time taken: 94.32\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8724\n",
      "Time taken: 94.45\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8686\n",
      "Time taken: 94.57\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8651\n",
      "Time taken: 94.69\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8722\n",
      "Time taken: 94.79\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8696\n",
      "Time taken: 94.92\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8660\n",
      "Time taken: 95.04\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8639\n",
      "Time taken: 95.16\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8672\n",
      "Time taken: 95.29\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8707\n",
      "Time taken: 95.43\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8749\n",
      "Time taken: 95.55\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8759\n",
      "Time taken: 95.68\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8723\n",
      "Time taken: 95.85\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8717\n",
      "Time taken: 96.05\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8731\n",
      "Time taken: 96.14\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8730\n",
      "Time taken: 96.28\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8751\n",
      "Time taken: 96.38\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8687\n",
      "Time taken: 96.51\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8691\n",
      "Time taken: 96.65\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8674\n",
      "Time taken: 96.79\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8716\n",
      "Time taken: 96.92\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8735\n",
      "Time taken: 97.06\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8729\n",
      "Time taken: 97.21\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8697\n",
      "Time taken: 97.34\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8688\n",
      "Time taken: 97.48\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8741\n",
      "Time taken: 97.61\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8729\n",
      "Time taken: 97.76\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8734\n",
      "Time taken: 97.88\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8700\n",
      "Time taken: 97.99\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8750\n",
      "Time taken: 98.13\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8721\n",
      "Time taken: 98.24\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8712\n",
      "Time taken: 98.38\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8730\n",
      "Time taken: 98.49\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8682\n",
      "Time taken: 98.63\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8726\n",
      "Time taken: 98.74\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8735\n",
      "Time taken: 98.88\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8669\n",
      "Time taken: 99.00\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8660\n",
      "Time taken: 99.13\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8740\n",
      "Time taken: 99.26\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8726\n",
      "Time taken: 99.39\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8736\n",
      "Time taken: 99.50\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8764\n",
      "Time taken: 99.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8763\n",
      "Time taken: 99.76\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8762\n",
      "Time taken: 99.89\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8771\n",
      "Time taken: 100.01\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8773\n",
      "Time taken: 100.13\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8743\n",
      "Time taken: 100.24\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8740\n",
      "Time taken: 100.37\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8777\n",
      "Time taken: 100.48\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8746\n",
      "Time taken: 100.61\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8736\n",
      "Time taken: 100.72\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8724\n",
      "Time taken: 100.86\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8722\n",
      "Time taken: 100.97\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8706\n",
      "Time taken: 101.14\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8731\n",
      "Time taken: 101.33\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8692\n",
      "Time taken: 101.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8720\n",
      "Time taken: 101.59\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8674\n",
      "Time taken: 101.71\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8678\n",
      "Time taken: 101.84\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8669\n",
      "Time taken: 101.96\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8734\n",
      "Time taken: 102.08\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8750\n",
      "Time taken: 102.19\n",
      "Training acc over epoch: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8753\n",
      "Time taken: 102.31\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8757\n",
      "Time taken: 102.42\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8711\n",
      "Time taken: 102.53\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8714\n",
      "Time taken: 102.66\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8712\n",
      "Time taken: 102.77\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8723\n",
      "Time taken: 102.89\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8722\n",
      "Time taken: 103.02\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8720\n",
      "Time taken: 103.12\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8735\n",
      "Time taken: 103.27\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8743\n",
      "Time taken: 103.39\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8728\n",
      "Time taken: 103.59\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.3458\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8695\n",
      "Time taken: 0.14\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8742\n",
      "Time taken: 0.27\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8723\n",
      "Time taken: 0.40\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8693\n",
      "Time taken: 0.54\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8609\n",
      "Time taken: 0.66\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8728\n",
      "Time taken: 0.79\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8726\n",
      "Time taken: 0.91\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8734\n",
      "Time taken: 1.06\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8748\n",
      "Time taken: 1.18\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8763\n",
      "Time taken: 1.31\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8750\n",
      "Time taken: 1.43\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8720\n",
      "Time taken: 1.58\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8737\n",
      "Time taken: 1.70\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8747\n",
      "Time taken: 1.84\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8698\n",
      "Time taken: 1.96\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8701\n",
      "Time taken: 2.10\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8640\n",
      "Time taken: 2.23\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8700\n",
      "Time taken: 2.36\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8714\n",
      "Time taken: 2.46\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8703\n",
      "Time taken: 2.60\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8661\n",
      "Time taken: 2.73\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8703\n",
      "Time taken: 2.89\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8679\n",
      "Time taken: 3.09\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8727\n",
      "Time taken: 3.22\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8670\n",
      "Time taken: 3.34\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8738\n",
      "Time taken: 3.46\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8757\n",
      "Time taken: 3.61\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8742\n",
      "Time taken: 3.73\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8733\n",
      "Time taken: 3.87\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8721\n",
      "Time taken: 3.98\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8689\n",
      "Time taken: 4.13\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8734\n",
      "Time taken: 4.26\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8754\n",
      "Time taken: 4.39\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8739\n",
      "Time taken: 4.51\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8744\n",
      "Time taken: 4.66\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8769\n",
      "Time taken: 4.78\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8756\n",
      "Time taken: 4.92\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8758\n",
      "Time taken: 5.03\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8767\n",
      "Time taken: 5.18\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8761\n",
      "Time taken: 5.30\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8756\n",
      "Time taken: 5.43\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8751\n",
      "Time taken: 5.55\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8764\n",
      "Time taken: 5.69\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8766\n",
      "Time taken: 5.81\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8735\n",
      "Time taken: 5.94\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8736\n",
      "Time taken: 6.06\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8752\n",
      "Time taken: 6.19\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8722\n",
      "Time taken: 6.30\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8729\n",
      "Time taken: 6.44\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8738\n",
      "Time taken: 6.56\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8706\n",
      "Time taken: 6.70\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8732\n",
      "Time taken: 6.82\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8746\n",
      "Time taken: 6.97\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8760\n",
      "Time taken: 7.08\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8770\n",
      "Time taken: 7.22\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8771\n",
      "Time taken: 7.34\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8757\n",
      "Time taken: 7.47\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8739\n",
      "Time taken: 7.59\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8741\n",
      "Time taken: 7.72\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8753\n",
      "Time taken: 7.85\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8779\n",
      "Time taken: 7.98\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8778\n",
      "Time taken: 8.11\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8780\n",
      "Time taken: 8.28\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8756\n",
      "Time taken: 8.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8769\n",
      "Time taken: 8.60\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8774\n",
      "Time taken: 8.73\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8760\n",
      "Time taken: 8.85\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8762\n",
      "Time taken: 9.00\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8749\n",
      "Time taken: 9.13\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8757\n",
      "Time taken: 9.28\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8760\n",
      "Time taken: 9.43\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8761\n",
      "Time taken: 9.57\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8783\n",
      "Time taken: 9.71\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8774\n",
      "Time taken: 9.85\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8763\n",
      "Time taken: 10.00\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8785\n",
      "Time taken: 10.14\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8792\n",
      "Time taken: 10.24\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8773\n",
      "Time taken: 10.37\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8785\n",
      "Time taken: 10.48\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8757\n",
      "Time taken: 10.60\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8767\n",
      "Time taken: 10.70\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8788\n",
      "Time taken: 10.83\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8800\n",
      "Time taken: 10.93\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8801\n",
      "Time taken: 11.07\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8716\n",
      "Time taken: 11.18\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8695\n",
      "Time taken: 11.32\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8774\n",
      "Time taken: 11.45\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8770\n",
      "Time taken: 11.57\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8763\n",
      "Time taken: 11.69\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8765\n",
      "Time taken: 11.83\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8748\n",
      "Time taken: 11.94\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8742\n",
      "Time taken: 12.09\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8723\n",
      "Time taken: 12.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8755\n",
      "Time taken: 12.34\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8751\n",
      "Time taken: 12.46\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8777\n",
      "Time taken: 12.59\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8784\n",
      "Time taken: 12.72\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8779\n",
      "Time taken: 12.85\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8801\n",
      "Time taken: 12.96\n",
      "Training acc over epoch: 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8804\n",
      "Time taken: 13.10\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8813\n",
      "Time taken: 13.22\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8787\n",
      "Time taken: 13.36\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8802\n",
      "Time taken: 13.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8696\n",
      "Time taken: 13.69\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8701\n",
      "Time taken: 13.86\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8827\n",
      "Time taken: 13.97\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8780\n",
      "Time taken: 14.09\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8769\n",
      "Time taken: 14.24\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8801\n",
      "Time taken: 14.35\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8796\n",
      "Time taken: 14.49\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8736\n",
      "Time taken: 14.61\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8745\n",
      "Time taken: 14.75\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8784\n",
      "Time taken: 14.88\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8779\n",
      "Time taken: 15.01\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8786\n",
      "Time taken: 15.13\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8788\n",
      "Time taken: 15.27\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8775\n",
      "Time taken: 15.38\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8795\n",
      "Time taken: 15.52\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8763\n",
      "Time taken: 15.66\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8797\n",
      "Time taken: 15.79\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8811\n",
      "Time taken: 15.91\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8743\n",
      "Time taken: 16.05\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8751\n",
      "Time taken: 16.16\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8752\n",
      "Time taken: 16.31\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8781\n",
      "Time taken: 16.43\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8783\n",
      "Time taken: 16.57\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8780\n",
      "Time taken: 16.69\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8792\n",
      "Time taken: 16.82\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8793\n",
      "Time taken: 16.93\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8577\n",
      "Time taken: 17.07\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8759\n",
      "Time taken: 17.18\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8782\n",
      "Time taken: 17.32\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8795\n",
      "Time taken: 17.45\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8779\n",
      "Time taken: 17.58\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8781\n",
      "Time taken: 17.70\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8781\n",
      "Time taken: 17.82\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8776\n",
      "Time taken: 17.95\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8771\n",
      "Time taken: 18.08\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8801\n",
      "Time taken: 18.20\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8794\n",
      "Time taken: 18.34\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8812\n",
      "Time taken: 18.47\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8824\n",
      "Time taken: 18.60\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8821\n",
      "Time taken: 18.73\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8824\n",
      "Time taken: 18.87\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8815\n",
      "Time taken: 19.07\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8803\n",
      "Time taken: 19.22\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8820\n",
      "Time taken: 19.34\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8843\n",
      "Time taken: 19.46\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8841\n",
      "Time taken: 19.60\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8821\n",
      "Time taken: 19.71\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8800\n",
      "Time taken: 19.85\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8799\n",
      "Time taken: 19.96\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8804\n",
      "Time taken: 20.11\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8820\n",
      "Time taken: 20.21\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8797\n",
      "Time taken: 20.36\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8801\n",
      "Time taken: 20.48\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8811\n",
      "Time taken: 20.62\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8824\n",
      "Time taken: 20.73\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8827\n",
      "Time taken: 20.86\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8836\n",
      "Time taken: 20.96\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8831\n",
      "Time taken: 21.10\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8846\n",
      "Time taken: 21.20\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8847\n",
      "Time taken: 21.34\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8849\n",
      "Time taken: 21.45\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8813\n",
      "Time taken: 21.58\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8802\n",
      "Time taken: 21.70\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8822\n",
      "Time taken: 21.84\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8805\n",
      "Time taken: 21.96\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8824\n",
      "Time taken: 22.10\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8828\n",
      "Time taken: 22.22\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8829\n",
      "Time taken: 22.36\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8830\n",
      "Time taken: 22.48\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8820\n",
      "Time taken: 22.60\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8816\n",
      "Time taken: 22.72\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8813\n",
      "Time taken: 22.84\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8805\n",
      "Time taken: 22.95\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8758\n",
      "Time taken: 23.10\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8797\n",
      "Time taken: 23.22\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8776\n",
      "Time taken: 23.36\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8776\n",
      "Time taken: 23.48\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8817\n",
      "Time taken: 23.62\n",
      "Training acc over epoch: 0.968750\n",
      "Validation acc: 0.8820\n",
      "Time taken: 23.76\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8815\n",
      "Time taken: 23.88\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8810\n",
      "Time taken: 24.01\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8802\n",
      "Time taken: 24.14\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8818\n",
      "Time taken: 24.32\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8818\n",
      "Time taken: 24.51\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8809\n",
      "Time taken: 24.62\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8790\n",
      "Time taken: 24.74\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8757\n",
      "Time taken: 24.85\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8770\n",
      "Time taken: 24.98\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8778\n",
      "Time taken: 25.14\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8792\n",
      "Time taken: 25.30\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8785\n",
      "Time taken: 25.48\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8802\n",
      "Time taken: 25.62\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8788\n",
      "Time taken: 25.76\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8804\n",
      "Time taken: 25.90\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8820\n",
      "Time taken: 26.04\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8826\n",
      "Time taken: 26.19\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8839\n",
      "Time taken: 26.30\n",
      "Training loss (for one batch) at step 200: 0.9799\n",
      "Seen so far: 12864 samples\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8810\n",
      "Time taken: 26.43\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8811\n",
      "Time taken: 26.55\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8812\n",
      "Time taken: 26.69\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8787\n",
      "Time taken: 26.81\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8782\n",
      "Time taken: 26.95\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8776\n",
      "Time taken: 27.06\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8818\n",
      "Time taken: 27.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8731\n",
      "Time taken: 27.33\n",
      "Training acc over epoch: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8816\n",
      "Time taken: 27.48\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8782\n",
      "Time taken: 27.60\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8776\n",
      "Time taken: 27.74\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8779\n",
      "Time taken: 27.86\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8809\n",
      "Time taken: 28.01\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8808\n",
      "Time taken: 28.13\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8798\n",
      "Time taken: 28.26\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8799\n",
      "Time taken: 28.38\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8737\n",
      "Time taken: 28.52\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8730\n",
      "Time taken: 28.65\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8803\n",
      "Time taken: 28.78\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8803\n",
      "Time taken: 28.90\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8795\n",
      "Time taken: 29.04\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8670\n",
      "Time taken: 29.16\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8686\n",
      "Time taken: 29.30\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8760\n",
      "Time taken: 29.41\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8779\n",
      "Time taken: 29.59\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8788\n",
      "Time taken: 29.77\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8761\n",
      "Time taken: 29.92\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8795\n",
      "Time taken: 30.04\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8774\n",
      "Time taken: 30.15\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8789\n",
      "Time taken: 30.28\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8780\n",
      "Time taken: 30.40\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8779\n",
      "Time taken: 30.53\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8758\n",
      "Time taken: 30.65\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8748\n",
      "Time taken: 30.78\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8747\n",
      "Time taken: 30.90\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8744\n",
      "Time taken: 31.03\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8731\n",
      "Time taken: 31.16\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8713\n",
      "Time taken: 31.29\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8681\n",
      "Time taken: 31.40\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8697\n",
      "Time taken: 31.54\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8723\n",
      "Time taken: 31.66\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8764\n",
      "Time taken: 31.80\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8772\n",
      "Time taken: 31.91\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8741\n",
      "Time taken: 32.06\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8800\n",
      "Time taken: 32.16\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8777\n",
      "Time taken: 32.31\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8774\n",
      "Time taken: 32.43\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8780\n",
      "Time taken: 32.56\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8780\n",
      "Time taken: 32.68\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8783\n",
      "Time taken: 32.82\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8785\n",
      "Time taken: 32.95\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8786\n",
      "Time taken: 33.08\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8787\n",
      "Time taken: 33.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8768\n",
      "Time taken: 33.34\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8783\n",
      "Time taken: 33.46\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8762\n",
      "Time taken: 33.60\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8744\n",
      "Time taken: 33.73\n",
      "Training acc over epoch: 0.968750\n",
      "Validation acc: 0.8750\n",
      "Time taken: 33.87\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8759\n",
      "Time taken: 33.99\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8749\n",
      "Time taken: 34.12\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8759\n",
      "Time taken: 34.23\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8788\n",
      "Time taken: 34.37\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8808\n",
      "Time taken: 34.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8826\n",
      "Time taken: 34.63\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8827\n",
      "Time taken: 34.75\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8831\n",
      "Time taken: 34.92\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8823\n",
      "Time taken: 35.09\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8812\n",
      "Time taken: 35.25\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8823\n",
      "Time taken: 35.36\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8825\n",
      "Time taken: 35.48\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8794\n",
      "Time taken: 35.58\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8828\n",
      "Time taken: 35.72\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8794\n",
      "Time taken: 35.83\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8802\n",
      "Time taken: 35.97\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8803\n",
      "Time taken: 36.10\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8785\n",
      "Time taken: 36.23\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8798\n",
      "Time taken: 36.33\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8818\n",
      "Time taken: 36.47\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8814\n",
      "Time taken: 36.58\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8778\n",
      "Time taken: 36.71\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8806\n",
      "Time taken: 36.81\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8835\n",
      "Time taken: 36.96\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8751\n",
      "Time taken: 37.08\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8769\n",
      "Time taken: 37.22\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8827\n",
      "Time taken: 37.33\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8833\n",
      "Time taken: 37.47\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8838\n",
      "Time taken: 37.58\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8832\n",
      "Time taken: 37.72\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8839\n",
      "Time taken: 37.85\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8824\n",
      "Time taken: 37.97\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8817\n",
      "Time taken: 38.09\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8816\n",
      "Time taken: 38.24\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8795\n",
      "Time taken: 38.36\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8789\n",
      "Time taken: 38.49\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8808\n",
      "Time taken: 38.62\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8824\n",
      "Time taken: 38.75\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8826\n",
      "Time taken: 38.88\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8826\n",
      "Time taken: 39.02\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8826\n",
      "Time taken: 39.15\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8825\n",
      "Time taken: 39.28\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8830\n",
      "Time taken: 39.40\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8831\n",
      "Time taken: 39.54\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8853\n",
      "Time taken: 39.66\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8812\n",
      "Time taken: 39.79\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8835\n",
      "Time taken: 39.90\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8795\n",
      "Time taken: 40.04\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8830\n",
      "Time taken: 40.17\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8804\n",
      "Time taken: 40.35\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8802\n",
      "Time taken: 40.54\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8820\n",
      "Time taken: 40.65\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8837\n",
      "Time taken: 40.78\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8799\n",
      "Time taken: 40.90\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8837\n",
      "Time taken: 41.04\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8828\n",
      "Time taken: 41.18\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8817\n",
      "Time taken: 41.32\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8808\n",
      "Time taken: 41.46\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8832\n",
      "Time taken: 41.60\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8829\n",
      "Time taken: 41.74\n",
      "Training acc over epoch: 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8839\n",
      "Time taken: 41.89\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8799\n",
      "Time taken: 42.01\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8818\n",
      "Time taken: 42.15\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8816\n",
      "Time taken: 42.26\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8836\n",
      "Time taken: 42.40\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8844\n",
      "Time taken: 42.51\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8854\n",
      "Time taken: 42.64\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8846\n",
      "Time taken: 42.76\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8784\n",
      "Time taken: 42.89\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8818\n",
      "Time taken: 43.01\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8810\n",
      "Time taken: 43.14\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8811\n",
      "Time taken: 43.25\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8798\n",
      "Time taken: 43.38\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8814\n",
      "Time taken: 43.48\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8782\n",
      "Time taken: 43.61\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8817\n",
      "Time taken: 43.73\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8829\n",
      "Time taken: 43.86\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8827\n",
      "Time taken: 43.97\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8820\n",
      "Time taken: 44.09\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8803\n",
      "Time taken: 44.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8831\n",
      "Time taken: 44.34\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8825\n",
      "Time taken: 44.45\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8812\n",
      "Time taken: 44.59\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8844\n",
      "Time taken: 44.71\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8824\n",
      "Time taken: 44.84\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8833\n",
      "Time taken: 44.96\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8832\n",
      "Time taken: 45.08\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8794\n",
      "Time taken: 45.20\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8842\n",
      "Time taken: 45.33\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8836\n",
      "Time taken: 45.45\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8761\n",
      "Time taken: 45.62\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8848\n",
      "Time taken: 45.79\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8838\n",
      "Time taken: 45.93\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8831\n",
      "Time taken: 46.05\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8842\n",
      "Time taken: 46.19\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8837\n",
      "Time taken: 46.31\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8827\n",
      "Time taken: 46.44\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8825\n",
      "Time taken: 46.57\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8817\n",
      "Time taken: 46.69\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8826\n",
      "Time taken: 46.82\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8821\n",
      "Time taken: 46.94\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8806\n",
      "Time taken: 47.08\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8820\n",
      "Time taken: 47.20\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8844\n",
      "Time taken: 47.33\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8801\n",
      "Time taken: 47.47\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8791\n",
      "Time taken: 47.60\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8806\n",
      "Time taken: 47.74\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8815\n",
      "Time taken: 47.86\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8794\n",
      "Time taken: 47.98\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8767\n",
      "Time taken: 48.11\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8813\n",
      "Time taken: 48.24\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8812\n",
      "Time taken: 48.36\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8821\n",
      "Time taken: 48.50\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8832\n",
      "Time taken: 48.61\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8824\n",
      "Time taken: 48.76\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8837\n",
      "Time taken: 48.88\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8825\n",
      "Time taken: 49.02\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8775\n",
      "Time taken: 49.13\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8824\n",
      "Time taken: 49.27\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8783\n",
      "Time taken: 49.39\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8789\n",
      "Time taken: 49.53\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8817\n",
      "Time taken: 49.65\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8817\n",
      "Time taken: 49.79\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8800\n",
      "Time taken: 49.91\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8823\n",
      "Time taken: 50.05\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8831\n",
      "Time taken: 50.18\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8834\n",
      "Time taken: 50.32\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8847\n",
      "Time taken: 50.44\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8834\n",
      "Time taken: 50.58\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8804\n",
      "Time taken: 50.70\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8832\n",
      "Time taken: 50.83\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8825\n",
      "Time taken: 50.99\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8828\n",
      "Time taken: 51.20\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8816\n",
      "Time taken: 51.32\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8801\n",
      "Time taken: 51.44\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8793\n",
      "Time taken: 51.55\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8763\n",
      "Time taken: 51.69\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8773\n",
      "Time taken: 51.82\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8808\n",
      "Time taken: 51.95\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8808\n",
      "Time taken: 52.08\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8780\n",
      "Time taken: 52.21\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8730\n",
      "Time taken: 52.33\n",
      "Training loss (for one batch) at step 400: 0.7277\n",
      "Seen so far: 25664 samples\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8823\n",
      "Time taken: 52.47\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8815\n",
      "Time taken: 52.58\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8828\n",
      "Time taken: 52.71\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8821\n",
      "Time taken: 52.83\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8805\n",
      "Time taken: 52.97\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8819\n",
      "Time taken: 53.08\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8779\n",
      "Time taken: 53.23\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8804\n",
      "Time taken: 53.35\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8829\n",
      "Time taken: 53.49\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8852\n",
      "Time taken: 53.60\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8825\n",
      "Time taken: 53.75\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8834\n",
      "Time taken: 53.86\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8852\n",
      "Time taken: 54.00\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8823\n",
      "Time taken: 54.13\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8837\n",
      "Time taken: 54.26\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8816\n",
      "Time taken: 54.38\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8807\n",
      "Time taken: 54.52\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8806\n",
      "Time taken: 54.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8786\n",
      "Time taken: 54.78\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8793\n",
      "Time taken: 54.90\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8768\n",
      "Time taken: 55.03\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8803\n",
      "Time taken: 55.15\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8787\n",
      "Time taken: 55.28\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8803\n",
      "Time taken: 55.40\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8787\n",
      "Time taken: 55.55\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8809\n",
      "Time taken: 55.66\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8785\n",
      "Time taken: 55.80\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8741\n",
      "Time taken: 55.93\n",
      "Training acc over epoch: 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8769\n",
      "Time taken: 56.07\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8774\n",
      "Time taken: 56.20\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8760\n",
      "Time taken: 56.38\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8766\n",
      "Time taken: 56.56\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8777\n",
      "Time taken: 56.67\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8786\n",
      "Time taken: 56.79\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8795\n",
      "Time taken: 56.93\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8775\n",
      "Time taken: 57.06\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8834\n",
      "Time taken: 57.20\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8863\n",
      "Time taken: 57.35\n",
      "Training acc over epoch: 0.750000\n",
      "Validation acc: 0.8819\n",
      "Time taken: 57.50\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8813\n",
      "Time taken: 57.65\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8793\n",
      "Time taken: 57.79\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8797\n",
      "Time taken: 57.93\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8799\n",
      "Time taken: 58.07\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8785\n",
      "Time taken: 58.19\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8800\n",
      "Time taken: 58.32\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8850\n",
      "Time taken: 58.43\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8848\n",
      "Time taken: 58.57\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8822\n",
      "Time taken: 58.68\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8804\n",
      "Time taken: 58.81\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8826\n",
      "Time taken: 58.93\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8833\n",
      "Time taken: 59.07\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8856\n",
      "Time taken: 59.20\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8825\n",
      "Time taken: 59.33\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8791\n",
      "Time taken: 59.45\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8796\n",
      "Time taken: 59.59\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8812\n",
      "Time taken: 59.71\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8828\n",
      "Time taken: 59.85\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8833\n",
      "Time taken: 59.96\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8810\n",
      "Time taken: 60.11\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8792\n",
      "Time taken: 60.23\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8797\n",
      "Time taken: 60.36\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8807\n",
      "Time taken: 60.48\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8810\n",
      "Time taken: 60.60\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8790\n",
      "Time taken: 60.72\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8806\n",
      "Time taken: 60.86\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8832\n",
      "Time taken: 60.98\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8812\n",
      "Time taken: 61.12\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8816\n",
      "Time taken: 61.23\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8817\n",
      "Time taken: 61.38\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8822\n",
      "Time taken: 61.50\n",
      "Training acc over epoch: 0.734375\n",
      "Validation acc: 0.8818\n",
      "Time taken: 61.69\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8822\n",
      "Time taken: 61.87\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8843\n",
      "Time taken: 61.98\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8800\n",
      "Time taken: 62.11\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8822\n",
      "Time taken: 62.23\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8814\n",
      "Time taken: 62.36\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8797\n",
      "Time taken: 62.48\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8819\n",
      "Time taken: 62.61\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8809\n",
      "Time taken: 62.71\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8821\n",
      "Time taken: 62.84\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8797\n",
      "Time taken: 62.96\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8819\n",
      "Time taken: 63.09\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8790\n",
      "Time taken: 63.20\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8784\n",
      "Time taken: 63.34\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8808\n",
      "Time taken: 63.45\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8807\n",
      "Time taken: 63.59\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8808\n",
      "Time taken: 63.70\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8780\n",
      "Time taken: 63.83\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8800\n",
      "Time taken: 63.95\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8784\n",
      "Time taken: 64.08\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8804\n",
      "Time taken: 64.20\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8786\n",
      "Time taken: 64.32\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8776\n",
      "Time taken: 64.42\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8798\n",
      "Time taken: 64.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8777\n",
      "Time taken: 64.67\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8796\n",
      "Time taken: 64.80\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8804\n",
      "Time taken: 64.91\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8784\n",
      "Time taken: 65.05\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8780\n",
      "Time taken: 65.17\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8760\n",
      "Time taken: 65.29\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8734\n",
      "Time taken: 65.40\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8833\n",
      "Time taken: 65.54\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8820\n",
      "Time taken: 65.65\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8800\n",
      "Time taken: 65.81\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8835\n",
      "Time taken: 65.93\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8792\n",
      "Time taken: 66.07\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8783\n",
      "Time taken: 66.19\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8814\n",
      "Time taken: 66.32\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8834\n",
      "Time taken: 66.43\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8640\n",
      "Time taken: 66.57\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8716\n",
      "Time taken: 66.69\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8775\n",
      "Time taken: 66.80\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8704\n",
      "Time taken: 66.96\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8860\n",
      "Time taken: 67.15\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8858\n",
      "Time taken: 67.30\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8847\n",
      "Time taken: 67.42\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8853\n",
      "Time taken: 67.53\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8866\n",
      "Time taken: 67.65\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8846\n",
      "Time taken: 67.77\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8834\n",
      "Time taken: 67.89\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8844\n",
      "Time taken: 68.01\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8823\n",
      "Time taken: 68.15\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8832\n",
      "Time taken: 68.27\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8834\n",
      "Time taken: 68.41\n",
      "Training acc over epoch: 0.968750\n",
      "Validation acc: 0.8848\n",
      "Time taken: 68.53\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8833\n",
      "Time taken: 68.67\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8832\n",
      "Time taken: 68.80\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8864\n",
      "Time taken: 68.93\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8849\n",
      "Time taken: 69.05\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8851\n",
      "Time taken: 69.18\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8840\n",
      "Time taken: 69.31\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8816\n",
      "Time taken: 69.44\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8820\n",
      "Time taken: 69.55\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8836\n",
      "Time taken: 69.67\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8848\n",
      "Time taken: 69.80\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8854\n",
      "Time taken: 69.93\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8836\n",
      "Time taken: 70.05\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8823\n",
      "Time taken: 70.19\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8845\n",
      "Time taken: 70.31\n",
      "Training acc over epoch: 0.906250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8845\n",
      "Time taken: 70.45\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8834\n",
      "Time taken: 70.58\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8838\n",
      "Time taken: 70.71\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8854\n",
      "Time taken: 70.83\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8845\n",
      "Time taken: 70.97\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8876\n",
      "Time taken: 71.08\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8864\n",
      "Time taken: 71.21\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8867\n",
      "Time taken: 71.33\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8861\n",
      "Time taken: 71.48\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8872\n",
      "Time taken: 71.60\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8874\n",
      "Time taken: 71.73\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8897\n",
      "Time taken: 71.86\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8846\n",
      "Time taken: 72.00\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8812\n",
      "Time taken: 72.13\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8832\n",
      "Time taken: 72.25\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8822\n",
      "Time taken: 72.46\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8817\n",
      "Time taken: 72.62\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8829\n",
      "Time taken: 72.72\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8883\n",
      "Time taken: 72.85\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8885\n",
      "Time taken: 72.96\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8879\n",
      "Time taken: 73.10\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8896\n",
      "Time taken: 73.25\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8884\n",
      "Time taken: 73.38\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8892\n",
      "Time taken: 73.52\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8885\n",
      "Time taken: 73.67\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8872\n",
      "Time taken: 73.80\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8891\n",
      "Time taken: 73.94\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8896\n",
      "Time taken: 74.09\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8896\n",
      "Time taken: 74.20\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8883\n",
      "Time taken: 74.34\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8875\n",
      "Time taken: 74.45\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8871\n",
      "Time taken: 74.59\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8862\n",
      "Time taken: 74.70\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8885\n",
      "Time taken: 74.83\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8910\n",
      "Time taken: 74.95\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8882\n",
      "Time taken: 75.07\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8894\n",
      "Time taken: 75.20\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8883\n",
      "Time taken: 75.30\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8875\n",
      "Time taken: 75.43\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8869\n",
      "Time taken: 75.56\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8852\n",
      "Time taken: 75.69\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8853\n",
      "Time taken: 75.82\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8851\n",
      "Time taken: 75.95\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8862\n",
      "Time taken: 76.08\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8872\n",
      "Time taken: 76.21\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8864\n",
      "Time taken: 76.35\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8860\n",
      "Time taken: 76.46\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8854\n",
      "Time taken: 76.61\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8860\n",
      "Time taken: 76.73\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8818\n",
      "Time taken: 76.87\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8856\n",
      "Time taken: 77.00\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8868\n",
      "Time taken: 77.13\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8867\n",
      "Time taken: 77.25\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8887\n",
      "Time taken: 77.39\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8886\n",
      "Time taken: 77.51\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8871\n",
      "Time taken: 77.69\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8821\n",
      "Time taken: 77.88\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8769\n",
      "Time taken: 78.00\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8795\n",
      "Time taken: 78.13\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8821\n",
      "Time taken: 78.25\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8790\n",
      "Time taken: 78.38\n",
      "Training loss (for one batch) at step 600: 0.5290\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8782\n",
      "Time taken: 78.50\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8843\n",
      "Time taken: 78.63\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8856\n",
      "Time taken: 78.75\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8815\n",
      "Time taken: 78.89\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8816\n",
      "Time taken: 79.00\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8862\n",
      "Time taken: 79.14\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8826\n",
      "Time taken: 79.27\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8862\n",
      "Time taken: 79.40\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8832\n",
      "Time taken: 79.50\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8835\n",
      "Time taken: 79.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8829\n",
      "Time taken: 79.75\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8859\n",
      "Time taken: 79.89\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8830\n",
      "Time taken: 80.02\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8847\n",
      "Time taken: 80.14\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8829\n",
      "Time taken: 80.26\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8834\n",
      "Time taken: 80.39\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8853\n",
      "Time taken: 80.50\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8861\n",
      "Time taken: 80.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8827\n",
      "Time taken: 80.73\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8838\n",
      "Time taken: 80.87\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8831\n",
      "Time taken: 81.01\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8834\n",
      "Time taken: 81.14\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8861\n",
      "Time taken: 81.26\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8866\n",
      "Time taken: 81.40\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8837\n",
      "Time taken: 81.53\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8825\n",
      "Time taken: 81.66\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8823\n",
      "Time taken: 81.78\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8831\n",
      "Time taken: 81.92\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8836\n",
      "Time taken: 82.05\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8827\n",
      "Time taken: 82.18\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8803\n",
      "Time taken: 82.30\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8816\n",
      "Time taken: 82.44\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8807\n",
      "Time taken: 82.57\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8832\n",
      "Time taken: 82.70\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8847\n",
      "Time taken: 82.83\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8830\n",
      "Time taken: 82.99\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8838\n",
      "Time taken: 83.18\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8844\n",
      "Time taken: 83.32\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8854\n",
      "Time taken: 83.44\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8856\n",
      "Time taken: 83.56\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8872\n",
      "Time taken: 83.70\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8866\n",
      "Time taken: 83.81\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8855\n",
      "Time taken: 83.94\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8871\n",
      "Time taken: 84.07\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8867\n",
      "Time taken: 84.20\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8864\n",
      "Time taken: 84.31\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8833\n",
      "Time taken: 84.45\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8841\n",
      "Time taken: 84.56\n",
      "Training acc over epoch: 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8842\n",
      "Time taken: 84.69\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8843\n",
      "Time taken: 84.81\n",
      "Training acc over epoch: 0.984375\n",
      "Validation acc: 0.8845\n",
      "Time taken: 84.95\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8821\n",
      "Time taken: 85.06\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8846\n",
      "Time taken: 85.21\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8835\n",
      "Time taken: 85.33\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8809\n",
      "Time taken: 85.47\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8771\n",
      "Time taken: 85.60\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8770\n",
      "Time taken: 85.73\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8830\n",
      "Time taken: 85.85\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8818\n",
      "Time taken: 85.99\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8816\n",
      "Time taken: 86.11\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8796\n",
      "Time taken: 86.25\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8818\n",
      "Time taken: 86.37\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8804\n",
      "Time taken: 86.51\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8827\n",
      "Time taken: 86.62\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8845\n",
      "Time taken: 86.76\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8842\n",
      "Time taken: 86.89\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8836\n",
      "Time taken: 87.01\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8853\n",
      "Time taken: 87.13\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8838\n",
      "Time taken: 87.27\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8844\n",
      "Time taken: 87.40\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8847\n",
      "Time taken: 87.52\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8831\n",
      "Time taken: 87.63\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8812\n",
      "Time taken: 87.77\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8843\n",
      "Time taken: 87.90\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8806\n",
      "Time taken: 88.03\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8723\n",
      "Time taken: 88.15\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8794\n",
      "Time taken: 88.30\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8824\n",
      "Time taken: 88.50\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8814\n",
      "Time taken: 88.65\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8807\n",
      "Time taken: 88.75\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8812\n",
      "Time taken: 88.90\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8816\n",
      "Time taken: 89.04\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8849\n",
      "Time taken: 89.18\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8841\n",
      "Time taken: 89.32\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8849\n",
      "Time taken: 89.48\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8848\n",
      "Time taken: 89.62\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8832\n",
      "Time taken: 89.76\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8839\n",
      "Time taken: 89.90\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8853\n",
      "Time taken: 90.04\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8858\n",
      "Time taken: 90.17\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8852\n",
      "Time taken: 90.28\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8849\n",
      "Time taken: 90.42\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8871\n",
      "Time taken: 90.54\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8866\n",
      "Time taken: 90.67\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8866\n",
      "Time taken: 90.78\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8872\n",
      "Time taken: 90.92\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8780\n",
      "Time taken: 91.04\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8805\n",
      "Time taken: 91.16\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8859\n",
      "Time taken: 91.27\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8859\n",
      "Time taken: 91.40\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8859\n",
      "Time taken: 91.52\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8852\n",
      "Time taken: 91.66\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8836\n",
      "Time taken: 91.76\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8840\n",
      "Time taken: 91.89\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8835\n",
      "Time taken: 92.02\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8812\n",
      "Time taken: 92.14\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8854\n",
      "Time taken: 92.25\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8833\n",
      "Time taken: 92.37\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8824\n",
      "Time taken: 92.48\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8850\n",
      "Time taken: 92.60\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8831\n",
      "Time taken: 92.72\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8828\n",
      "Time taken: 92.85\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8807\n",
      "Time taken: 92.97\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8865\n",
      "Time taken: 93.11\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8856\n",
      "Time taken: 93.24\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8846\n",
      "Time taken: 93.37\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8831\n",
      "Time taken: 93.50\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8839\n",
      "Time taken: 93.65\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8858\n",
      "Time taken: 93.85\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8860\n",
      "Time taken: 93.98\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8845\n",
      "Time taken: 94.11\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8848\n",
      "Time taken: 94.23\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8822\n",
      "Time taken: 94.35\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8846\n",
      "Time taken: 94.47\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8765\n",
      "Time taken: 94.60\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8818\n",
      "Time taken: 94.73\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8844\n",
      "Time taken: 94.87\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8831\n",
      "Time taken: 94.98\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8858\n",
      "Time taken: 95.12\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8840\n",
      "Time taken: 95.25\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8821\n",
      "Time taken: 95.38\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8845\n",
      "Time taken: 95.50\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8853\n",
      "Time taken: 95.63\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8859\n",
      "Time taken: 95.73\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8821\n",
      "Time taken: 95.88\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8851\n",
      "Time taken: 96.00\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8838\n",
      "Time taken: 96.14\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8860\n",
      "Time taken: 96.27\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8822\n",
      "Time taken: 96.40\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8835\n",
      "Time taken: 96.51\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8840\n",
      "Time taken: 96.64\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8842\n",
      "Time taken: 96.77\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8845\n",
      "Time taken: 96.90\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8862\n",
      "Time taken: 97.03\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8855\n",
      "Time taken: 97.17\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8872\n",
      "Time taken: 97.30\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8807\n",
      "Time taken: 97.43\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8855\n",
      "Time taken: 97.55\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8872\n",
      "Time taken: 97.69\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8877\n",
      "Time taken: 97.81\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8851\n",
      "Time taken: 97.96\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8872\n",
      "Time taken: 98.08\n",
      "Training acc over epoch: 0.796875\n",
      "Validation acc: 0.8869\n",
      "Time taken: 98.22\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8869\n",
      "Time taken: 98.33\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8872\n",
      "Time taken: 98.49\n",
      "Training acc over epoch: 0.921875\n",
      "Validation acc: 0.8876\n",
      "Time taken: 98.61\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8843\n",
      "Time taken: 98.75\n",
      "Training acc over epoch: 0.953125\n",
      "Validation acc: 0.8857\n",
      "Time taken: 98.86\n",
      "Training acc over epoch: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8838\n",
      "Time taken: 99.05\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8802\n",
      "Time taken: 99.24\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8859\n",
      "Time taken: 99.37\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8844\n",
      "Time taken: 99.49\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8873\n",
      "Time taken: 99.62\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8841\n",
      "Time taken: 99.75\n",
      "Training acc over epoch: 0.781250\n",
      "Validation acc: 0.8835\n",
      "Time taken: 99.88\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8884\n",
      "Time taken: 100.01\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8881\n",
      "Time taken: 100.13\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8877\n",
      "Time taken: 100.29\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8872\n",
      "Time taken: 100.40\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8863\n",
      "Time taken: 100.53\n",
      "Training acc over epoch: 0.937500\n",
      "Validation acc: 0.8867\n",
      "Time taken: 100.65\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8831\n",
      "Time taken: 100.79\n",
      "Training acc over epoch: 0.906250\n",
      "Validation acc: 0.8887\n",
      "Time taken: 100.91\n",
      "Training acc over epoch: 0.859375\n",
      "Validation acc: 0.8893\n",
      "Time taken: 101.04\n",
      "Training acc over epoch: 0.890625\n",
      "Validation acc: 0.8888\n",
      "Time taken: 101.15\n",
      "Training acc over epoch: 0.765625\n",
      "Validation acc: 0.8865\n",
      "Time taken: 101.30\n",
      "Training acc over epoch: 0.828125\n",
      "Validation acc: 0.8894\n",
      "Time taken: 101.41\n",
      "Training acc over epoch: 0.875000\n",
      "Validation acc: 0.8860\n",
      "Time taken: 101.56\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8853\n",
      "Time taken: 101.69\n",
      "Training acc over epoch: 0.812500\n",
      "Validation acc: 0.8843\n",
      "Time taken: 101.82\n",
      "Training acc over epoch: 0.843750\n",
      "Validation acc: 0.8873\n",
      "Time taken: 101.95\n",
      "Training acc over epoch: 1.000000\n",
      "Validation acc: 0.8860\n",
      "Time taken: 102.08\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\"%(epoch,))\n",
    "    start_time = time.time()\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        if step % 200 == 0:\n",
    "            print(\"Training loss (for one batch) at step %d: %.4f\"%(step, float(loss_value)))\n",
    "            print(\"Seen so far: %d samples\"%((step + 1) * batch_size))\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print(\"Training acc over epoch: %4f\"%(float(train_acc)))\n",
    "        train_acc_metric.reset_states()\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\"%(float(val_acc)))\n",
    "        print(\"Time taken: %.2f\"%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "580da5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(1e-2 * tf.reduce_sum(inputs))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4824b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =keras.Input(shape=(784, ), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5228609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "        loss_value += sum(model.losses)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7074a8bb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa9e09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 74,625\n",
      "Trainable params: 74,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dense(1)\n",
    "], name=\"discriminator\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7ed4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "generator = keras.Sequential([\n",
    "    keras.Input(shape=(latent_dim)),\n",
    "    layers.Dense(7 * 7 * 128),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    layers.Reshape((7, 7, 128)),\n",
    "    layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "], name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d23aa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "    labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0)\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(combined_images)\n",
    "        d_loss = loss_fn(labels, predictions)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    misleading_labels = tf.zeros((batch_size, 1))\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "    return d_loss, g_loss, generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed45cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start epoch 0\n",
      "discriminator loss at step 0:0.67\n",
      "adversarial loss at step 0: 0.70\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\")/255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "epochs = 1\n",
    "save_dir = \"./\"\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "    for step, real_images in enumerate(dataset):\n",
    "        d_loss, g_loss, generated_images = train_step(real_images)\n",
    "        if step % 200 == 0:\n",
    "            print(\"discriminator loss at step %d:%.2f\" %(step, d_loss))\n",
    "            print(\"adversarial loss at step %d: %.2f\" %(step, g_loss))\n",
    "            img = tf.keras.preprocessing.image.array_to_img(\n",
    "            generated_images[0] * 255.0, scale=False)\n",
    "            img.save(os.path.join(save_dir, \"generated_img\" + str(step) + \".png\"))\n",
    "        if step > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4227ca4",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks(RNN) with keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9d5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101db144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         247296    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09892212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "encoder_input = layers.Input(shape=(None, ))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "decoder_output = layers.LSTM(64, name=\"decoder\")(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "model = keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7064dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b186228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "existing_state = lstm_layer.states\n",
    "new_lstm_layer = layers.LSTM(64)\n",
    "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b895ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2deda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_dim = 28\n",
    "units = 64\n",
    "output_size = 10\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    if allow_cudnn_kernel:\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        lstm_layer = keras.layers.RNN(keras.layers.LSTMCell(units), input_shape=(None, input_dim))\n",
    "    model = keras.models.Sequential([\n",
    "        lstm_layer,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(output_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbf0c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd24268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 29s 28ms/step - loss: 0.9436 - accuracy: 0.7049 - val_loss: 0.6149 - val_accuracy: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19693497850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6acc23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 26s 26ms/step - loss: 0.3856 - accuracy: 0.8830 - val_loss: 0.3156 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19683bab400>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
    "noncudnn_model.set_weights(model.get_weights())\n",
    "noncudnn_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"sgd\", \n",
    "                       metrics=[\"accuracy\"])\n",
    "noncudnn_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758868b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRedicted result is: [3], target result is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with tf.device(\"CPU:0\"):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "    print(\"PRedicted result is: %s, target result is: %s\"%(result.numpy(), sample_label))\n",
    "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de304bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedCell(keras.layers.Layer):\n",
    "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
    "        self.unit_1 = unit_1\n",
    "        self.unit_2 = unit_2\n",
    "        self.unit_3 = unit_3\n",
    "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        super(NestedCell, self).__init__(**kwargs)\n",
    "    def build(self, input_shapes):\n",
    "        i1 = input_shapes[0][1]\n",
    "        i2 = input_shapes[1][1]\n",
    "        i3 = input_shapes[1][2]\n",
    "        self.kernel_1 = self.add_weight(shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\")\n",
    "        self.kernel_2_3 = self.add_weight(shape=(i2, i3, self.unit_2, self.unit_3), initializer=\"uniform\",\n",
    "                                          name=\"kernel_2_3\")\n",
    "    def call(self, inputs, states):\n",
    "        input_1, input_2 = tf.nest.flatten(inputs)\n",
    "        s1, s2 = states\n",
    "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
    "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
    "        state_1 = s1 + output_1\n",
    "        state_2_3 = s2 + output_2_3\n",
    "        output = (output_1, output_2_3)\n",
    "        new_states = (state_1, state_2_3)\n",
    "        return output, new_states\n",
    "    def get_config(self):\n",
    "        return {\"unit_1\":self.unit_1, \"unit_2\":unit_2, \"unit_3\":self.unit_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "781d3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "i1 = 32\n",
    "i2 = 64\n",
    "i3 = 32\n",
    "batch_size = 64\n",
    "num_batches = 10\n",
    "timestep = 50\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = keras.layers.RNN(cell)\n",
    "input_1 = keras.Input((None, i1))\n",
    "input_2 = keras.Input((None, i2, i3))\n",
    "outputs = rnn((input_1, input_2))\n",
    "model = keras.models.Model([input_1, input_2], outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efcad5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 558ms/step - loss: 0.7910 - rnn_5_loss: 0.3098 - rnn_5_1_loss: 0.4812 - rnn_5_accuracy: 0.1125 - rnn_5_1_accuracy: 0.0316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19687bce370>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
    "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
    "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f9f2b",
   "metadata": {},
   "source": [
    "# Masking and Padding with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f1999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0cd141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215  927    0    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs, padding=\"post\")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970267e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True False False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True False False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "print(masked_output._keras_mask)\n",
    "masking_layer = layers.Masking()\n",
    "unmasked_embedding = tf.cast(tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32)\n",
    "masked_embedding = masking_layer(unmasked_embedding)\n",
    "print(masked_embedding._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8e5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n",
       "array([[-0.00360916, -0.00803302,  0.00171674, ...,  0.00016223,\n",
       "         0.00148715, -0.00147442],\n",
       "       [-0.00170185,  0.00493712, -0.00307632, ..., -0.00229336,\n",
       "         0.00434857,  0.0086675 ],\n",
       "       [-0.00043115,  0.00151275,  0.00215201, ...,  0.00168387,\n",
       "         0.00490442,  0.00368921],\n",
       "       ...,\n",
       "       [ 0.01494942,  0.01233144,  0.01274616, ...,  0.00075365,\n",
       "        -0.00425649,  0.00588885],\n",
       "       [-0.00026004, -0.00755671,  0.00382418, ...,  0.00867608,\n",
       "         0.00312251, -0.00772895],\n",
       "       [-0.00536768, -0.00344387,  0.00647719, ...,  0.00762294,\n",
       "        -0.01317572, -0.00651452]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(32)\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        output = self.lstm(x, mask=mask)\n",
    "        return output\n",
    "layer = MyLayer()\n",
    "x = np.random.random((32, 10)) * 100\n",
    "x = x.astype(\"int32\")\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b8e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False False False]\n",
      " [ True False False]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "class TemporalSplit(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.split(inputs, 2, axis=1)\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        return tf.split(mask, 2, axis=1)\n",
    "first_half, second_half = TemporalSplit()(masked_embedding)\n",
    "print(first_half._keras_mask)\n",
    "print(second_half._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28817372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [False False  True  True  True  True  True  True  True  True]\n",
      " [False  True  True  True  True  True False  True  True False]], shape=(3, 10), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "class CustomEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n",
    "        super(CustomEmbedding, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.mask_zero = mask_zero\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = self.add_weight(shape=(self.input_dim, self.output_dim), initializer=\"random_normal\", \n",
    "                                         dtype=\"float32\")\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup(self.embedding, inputs)\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if not self.mask_zero:\n",
    "            return None\n",
    "        return tf.not_equal(inputs, 0)\n",
    "layer = CustomEmbedding(10, 32, mask_zero=True)\n",
    "x = np.random.random((3, 10)) * 9\n",
    "x = x.astype(\"int32\")\n",
    "y = layer(x)\n",
    "mask = layer.compute_mask(x)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63c6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyActivation(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyActivation, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcb4570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask found: KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.bool, name=None), name='Placeholder_1:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None, ), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "x = MyActivation()(x)\n",
    "print(\"Mask found:\",x._keras_mask)\n",
    "outputs = layers.LSTM(32)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3498a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSoftmax(keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        inputs_exp = tf.exp(inputs) * broadcast_float_mask\n",
    "        inputs_sum = tf.reduce_sum(inputs_exp * broadcast_float_mask, axis = -1, keepdims=True)\n",
    "        return inputs_exp / inputs_sum\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=10, output_dim=32, mask_zero=True)(inputs)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = TemporalSoftmax()(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "y = model(np.random.randint(0, 10, size=(32, 100)), np.random.random((32, 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444dd4e",
   "metadata": {},
   "source": [
    "# keras.callbacks.Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e337dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(1, input_dim=784))\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.1), loss=\"mean_squared_error\",\n",
    "                  metrics=[\"mean_absolute_error\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\")/255.0\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\")/255.0\n",
    "x_train = x_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2281852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "    def on_test_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start testing; got log keys: {}\".format(keys))\n",
    "    def on_test_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "    def on_predict_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: start of batch {}: got log keys: {}\".format(batch, keys))\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cfcd747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training; got log keys: []\n",
      "End epoch 0 of training; got log keys: []\n",
      "...Training: start of batch 0; got log keys: []\n",
      "...Evaluating: start of batch 0: got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 1; got log keys: []\n",
      "...Evaluating: start of batch 1: got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 2; got log keys: []\n",
      "...Evaluating: start of batch 2: got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 3; got log keys: []\n",
      "...Evaluating: start of batch 3: got log keys: ['loss', 'mean_absolute_error']\n",
      "Start testing; got log keys: []\n",
      "...Evaluating: end of batch 0; got log keys: []\n",
      "...Evaluating: end of batch 0; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 1; got log keys: []\n",
      "...Evaluating: end of batch 1; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 2; got log keys: []\n",
      "...Evaluating: end of batch 2; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 3; got log keys: []\n",
      "...Evaluating: end of batch 3; got log keys: ['loss', 'mean_absolute_error']\n",
      "Stop testing; got log keys: ['loss', 'mean_absolute_error']\n",
      "End epoch 0 of training; got log keys: ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']\n",
      "Stop training; got log keys: ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']\n",
      "Start testing; got log keys: []\n",
      "...Evaluating: end of batch 0; got log keys: []\n",
      "...Evaluating: end of batch 0; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 1; got log keys: []\n",
      "...Evaluating: end of batch 1; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 2; got log keys: []\n",
      "...Evaluating: end of batch 2; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 3; got log keys: []\n",
      "...Evaluating: end of batch 3; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 4; got log keys: []\n",
      "...Evaluating: end of batch 4; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 5; got log keys: []\n",
      "...Evaluating: end of batch 5; got log keys: ['loss', 'mean_absolute_error']\n",
      "WARNING:tensorflow:Callback method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0013s). Check your callbacks.\n",
      "...Evaluating: end of batch 6; got log keys: []\n",
      "...Evaluating: end of batch 6; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: end of batch 7; got log keys: []\n",
      "...Evaluating: end of batch 7; got log keys: ['loss', 'mean_absolute_error']\n",
      "Stop testing; got log keys: ['loss', 'mean_absolute_error']\n",
      "Stop predicting; got log keys: []\n",
      "...Predicting: start of batch 0; got log keys: []\n",
      "...Predicting: end of batch 0; got log keys: ['outputs']\n",
      "...Predicting: start of batch 1; got log keys: []\n",
      "...Predicting: end of batch 1; got log keys: ['outputs']\n",
      "...Predicting: start of batch 2; got log keys: []\n",
      "...Predicting: end of batch 2; got log keys: ['outputs']\n",
      "...Predicting: start of batch 3; got log keys: []\n",
      "...Predicting: end of batch 3; got log keys: ['outputs']\n",
      "...Predicting: start of batch 4; got log keys: []\n",
      "...Predicting: end of batch 4; got log keys: ['outputs']\n",
      "...Predicting: start of batch 5; got log keys: []\n",
      "...Predicting: end of batch 5; got log keys: ['outputs']\n",
      "...Predicting: start of batch 6; got log keys: []\n",
      "...Predicting: end of batch 6; got log keys: ['outputs']\n",
      "...Predicting: start of batch 7; got log keys: []\n",
      "...Predicting: end of batch 7; got log keys: ['outputs']\n",
      "Stop predicting; got log keys: []\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=0, validation_split=0.5, callbacks=[CustomCallback()])\n",
    "res = model.evaluate(x_test, y_test, batch_size=128, verbose=0, callbacks=[CustomCallback()])\n",
    "res = model.predict(x_test, batch_size=128, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22365e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to batch 0, the average loss is   26.85\n",
      "Up to batch 1, the average loss is  462.78\n",
      "Up to batch 2, the average loss is  316.08\n",
      "Up to batch 3, the average loss is  239.36\n",
      "Up to batch 4, the average loss is  192.76\n",
      "Up to batch 5, the average loss is  161.97\n",
      "Up to batch 6, the average loss is  139.64\n",
      "Up to batch 7, the average loss is  125.62\n",
      "Up to batch 0, the average loss is    5.21\n",
      "Up to batch 1, the average loss is    4.92\n",
      "Up to batch 2, the average loss is    4.46\n",
      "Up to batch 3, the average loss is    4.56\n",
      "Up to batch 4, the average loss is    4.57\n",
      "Up to batch 5, the average loss is    4.61\n",
      "Up to batch 6, the average loss is    4.64\n",
      "Up to batch 7, the average loss is    4.50\n",
      "Up to batch 0, the average loss is    4.98\n",
      "Up to batch 1, the average loss is    4.42\n",
      "Up to batch 2, the average loss is    4.39\n",
      "Up to batch 3, the average loss is    4.38\n",
      "Up to batch 4, the average loss is    4.54\n",
      "Up to batch 5, the average loss is    4.53\n",
      "Up to batch 6, the average loss is    4.49\n",
      "Up to batch 7, the average loss is    4.43\n"
     ]
    }
   ],
   "source": [
    "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"Up to batch {}, the average loss is {:7.2f}\".format(batch, logs[\"loss\"]))\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\"Up to batch {}, the average loss is {:7.2f}\".format(batch, logs[\"loss\"]))\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         print(\"The average loss for epoch {} is {:.7.2f} and mean absolute error is {:7.2f}\".format(epoch, logs[\"loss\"], \n",
    "#                                                                                                      logs[\"mean_absolute_error\"]))\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=0, callbacks=[LossAndErrorPrintingCallback()])\n",
    "res = model.evaluate(x_test, y_test, batch_size=128, verbose=0, callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50586182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to batch 0, the average loss is   30.36\n",
      "Up to batch 1, the average loss is  467.80\n",
      "Up to batch 2, the average loss is  321.18\n",
      "Up to batch 3, the average loss is  243.67\n",
      "Up to batch 4, the average loss is  196.77\n",
      "Up to batch 0, the average loss is    5.15\n",
      "Up to batch 1, the average loss is    5.84\n",
      "Up to batch 2, the average loss is    5.47\n",
      "Up to batch 3, the average loss is    5.56\n",
      "Up to batch 4, the average loss is    5.49\n",
      "Up to batch 0, the average loss is    5.16\n",
      "Up to batch 1, the average loss is    6.28\n",
      "Up to batch 2, the average loss is    7.54\n",
      "Up to batch 3, the average loss is    8.65\n",
      "Up to batch 4, the average loss is    9.46\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d28020850>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" %(self.stopped_epoch + 1))\n",
    "\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=64, steps_per_epoch=5, epochs=30, verbose=0, \n",
    "          callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12b248c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: Learning rate is 0.1000.\n",
      "Up to batch 0, the average loss is   25.44\n",
      "Up to batch 1, the average loss is  478.64\n",
      "Up to batch 2, the average loss is  327.19\n",
      "Up to batch 3, the average loss is  247.47\n",
      "Up to batch 4, the average loss is  199.96\n",
      "\n",
      "Epoch 00001: Learning rate is 0.1000.\n",
      "Up to batch 0, the average loss is    7.63\n",
      "Up to batch 1, the average loss is    6.32\n",
      "Up to batch 2, the average loss is    6.74\n",
      "Up to batch 3, the average loss is    6.43\n",
      "Up to batch 4, the average loss is    6.00\n",
      "\n",
      "Epoch 00002: Learning rate is 0.1000.\n",
      "Up to batch 0, the average loss is    4.83\n",
      "Up to batch 1, the average loss is    4.54\n",
      "Up to batch 2, the average loss is    4.40\n",
      "Up to batch 3, the average loss is    4.70\n",
      "Up to batch 4, the average loss is    4.70\n",
      "\n",
      "Epoch 00003: Learning rate is 0.0500.\n",
      "Up to batch 0, the average loss is    7.00\n",
      "Up to batch 1, the average loss is    5.94\n",
      "Up to batch 2, the average loss is    5.34\n",
      "Up to batch 3, the average loss is    4.86\n",
      "Up to batch 4, the average loss is    4.68\n",
      "\n",
      "Epoch 00004: Learning rate is 0.0500.\n",
      "Up to batch 0, the average loss is    5.24\n",
      "Up to batch 1, the average loss is    4.69\n",
      "Up to batch 2, the average loss is    4.30\n",
      "Up to batch 3, the average loss is    4.44\n",
      "Up to batch 4, the average loss is    4.24\n",
      "\n",
      "Epoch 00005: Learning rate is 0.0500.\n",
      "Up to batch 0, the average loss is    4.97\n",
      "Up to batch 1, the average loss is    5.03\n",
      "Up to batch 2, the average loss is    4.50\n",
      "Up to batch 3, the average loss is    4.45\n",
      "Up to batch 4, the average loss is    4.27\n",
      "\n",
      "Epoch 00006: Learning rate is 0.0100.\n",
      "Up to batch 0, the average loss is    3.54\n",
      "Up to batch 1, the average loss is    3.20\n",
      "Up to batch 2, the average loss is    3.29\n",
      "Up to batch 3, the average loss is    3.42\n",
      "Up to batch 4, the average loss is    3.37\n",
      "\n",
      "Epoch 00007: Learning rate is 0.0100.\n",
      "Up to batch 0, the average loss is    4.13\n",
      "Up to batch 1, the average loss is    4.01\n",
      "Up to batch 2, the average loss is    3.97\n",
      "Up to batch 3, the average loss is    3.67\n",
      "Up to batch 4, the average loss is    3.53\n",
      "\n",
      "Epoch 00008: Learning rate is 0.0100.\n",
      "Up to batch 0, the average loss is    3.28\n",
      "Up to batch 1, the average loss is    3.04\n",
      "Up to batch 2, the average loss is    3.15\n",
      "Up to batch 3, the average loss is    3.10\n",
      "Up to batch 4, the average loss is    3.16\n",
      "\n",
      "Epoch 00009: Learning rate is 0.0050.\n",
      "Up to batch 0, the average loss is    2.96\n",
      "Up to batch 1, the average loss is    3.44\n",
      "Up to batch 2, the average loss is    3.59\n",
      "Up to batch 3, the average loss is    3.63\n",
      "Up to batch 4, the average loss is    3.51\n",
      "\n",
      "Epoch 00010: Learning rate is 0.0050.\n",
      "Up to batch 0, the average loss is    2.28\n",
      "Up to batch 1, the average loss is    2.87\n",
      "Up to batch 2, the average loss is    3.28\n",
      "Up to batch 3, the average loss is    3.24\n",
      "Up to batch 4, the average loss is    3.16\n",
      "\n",
      "Epoch 00011: Learning rate is 0.0050.\n",
      "Up to batch 0, the average loss is    2.65\n",
      "Up to batch 1, the average loss is    2.82\n",
      "Up to batch 2, the average loss is    3.11\n",
      "Up to batch 3, the average loss is    3.35\n",
      "Up to batch 4, the average loss is    3.52\n",
      "\n",
      "Epoch 00012: Learning rate is 0.0010.\n",
      "Up to batch 0, the average loss is    2.90\n",
      "Up to batch 1, the average loss is    3.04\n",
      "Up to batch 2, the average loss is    3.30\n",
      "Up to batch 3, the average loss is    3.14\n",
      "Up to batch 4, the average loss is    3.12\n",
      "\n",
      "Epoch 00013: Learning rate is 0.0010.\n",
      "Up to batch 0, the average loss is    2.61\n",
      "Up to batch 1, the average loss is    3.19\n",
      "Up to batch 2, the average loss is    3.26\n",
      "Up to batch 3, the average loss is    3.03\n",
      "Up to batch 4, the average loss is    3.38\n",
      "\n",
      "Epoch 00014: Learning rate is 0.0010.\n",
      "Up to batch 0, the average loss is    3.13\n",
      "Up to batch 1, the average loss is    2.78\n",
      "Up to batch 2, the average loss is    3.22\n",
      "Up to batch 3, the average loss is    3.07\n",
      "Up to batch 4, the average loss is    2.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d27b0efd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLeariningRateScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLeariningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError(\"Optimizer must have a \\\"lr\\\" attribute\")\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        schedule_lr = self.schedule(epoch, lr)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, schedule_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\"%(epoch, schedule_lr))\n",
    "LR_SCHEDULE = [\n",
    "    (3, 0.05),\n",
    "    (6, 0.01),\n",
    "    (9, 0.005),\n",
    "    (12, 0.001)\n",
    "]\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr\n",
    "\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=64, steps_per_epoch=5, epochs=15, verbose=0, \n",
    "          callbacks=[LossAndErrorPrintingCallback(), CustomLeariningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf08fe2",
   "metadata": {},
   "source": [
    "# Transfer leaning and fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8ebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbf75ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "trainable_weights: 2\n",
      "non_trainable_weights 0\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build((None, 4))\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf336cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 4\n",
      "trainable weights 2\n",
      "non_trainable_weights 2\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.BatchNormalization()\n",
    "layer.build((None, 4))\n",
    "print(\"weights\", len(layer.weights))\n",
    "print(\"trainable weights\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2f0116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 2\n",
      "trainable_weights 0\n",
      "non_trainable_weights 2\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build((None, 4))\n",
    "layer.trainable = False\n",
    "print(\"weights\", len(layer.weights))\n",
    "print(\"trainable_weights\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22af2d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0495\n"
     ]
    }
   ],
   "source": [
    "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
    "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
    "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
    "layer1.trainable = False\n",
    "initial_layer1_weights_values = layer1.get_weights()\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
    "final_layer1_weights_values = layer1.get_weights()\n",
    "np.testing.assert_allclose(initial_layer1_weights_values[0], final_layer1_weights_values[0])\n",
    "np.testing.assert_allclose(initial_layer1_weights_values[1], final_layer1_weights_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c7c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model = keras.Sequential([\n",
    "    keras.Input(shape=(3,)),\n",
    "    keras.layers.Dense(3, activation=\"relu\"),\n",
    "    keras.layers.Dense(3, activation=\"relu\")\n",
    "])\n",
    "model = keras.Sequential([keras.Input(shape=(3, )), inner_model, keras.layers.Dense(3, activation=\"sigmoid\")])\n",
    "model.trainable = False\n",
    "assert inner_model.trainable == False\n",
    "assert inner_model.layers[0].trainable == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9287422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(weights=\"imagenet\", input_shape=(150, 150, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0d4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1166e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss=keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "             metrics=[keras.metrics.BinaryAccuracy()])\n",
    "model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab60cccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fc066be52c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(weights=\"imagenet\", input_shape=(150, 150, 3), include_top=False)\n",
    "base_model.trainable=False\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "for inputs, targets in new_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss_value = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebf885",
   "metadata": {},
   "source": [
    "# Training Keras models with Tensorflow Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f789efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_cloud as tfc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3279c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 33s 76ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9745\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.0769 - val_sparse_categorical_accuracy: 0.9787\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9863\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 33s 77ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.0425 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 0.9868\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0381 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 31s 74ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9908\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 32s 75ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0422 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 32s 75ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 32s 75ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0392 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 31s 74ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0353 - val_sparse_categorical_accuracy: 0.9912\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 32s 75ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9858\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0422 - val_sparse_categorical_accuracy: 0.9902\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0371 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 31s 75ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0374 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0372 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 31s 74ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0456 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0463 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0451 - val_sparse_categorical_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b05b732a30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28)),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255),\n",
    "    layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=keras.metrics.SparseCategoricalAccuracy())\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a718c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(28, 28)),\n",
    "        layers.experimental.preprocessing.Rescaling(1.0/255),\n",
    "        layers.Reshape(target_shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=keras.metrics.SparseCategoricalAccuracy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44a74334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "gcp_bucket = \"keras-examples\"\n",
    "checkpoint_path = os.path.join(\"gs://\", gcp_bucket, \"mnist_example\", \"save_at_{epoch}\")\n",
    "tensorflow_path = os.path.join(\"gs://\", gcp_bucket, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [keras.callbacks.TensorBoard(log_dir=tensorflow_path, histogram_freq=1), \n",
    "            keras.callbacks.ModelCheckpoint(checkpoint_path), \n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)]\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb99657",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebceba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.2173 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 38s 40ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 38s 40ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9862\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9888 3s - loss: 0.0346 - sparse_categ - ETA: 1s - loss: 0.0352 - sparse_ca\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 38s 40ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b05b8b87f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if tfc.remote():\n",
    "    epochs = 100\n",
    "    callbacks = callbacks\n",
    "    batch_size = 128\n",
    "else:\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    callbacks = None\n",
    "model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f8424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"gs://\", gcp_bucket, \"mnist_example\")\n",
    "if tfc.remote():\n",
    "    model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f75d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unknown keyword arguments: dict_keys(['docker_image_name'])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-1f0756dd7b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tfc.run(docker_image_name=gcp_bucket,\n\u001b[0m\u001b[0;32m      2\u001b[0m        \u001b[0mchief_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMMON_MACHINE_CONFIGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m        \u001b[0mworker_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        worker_config=tfc.COMMON_MACHINE_CONFIGS['T4_4X'])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_cloud\\core\\run.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(entry_point, requirements_txt, docker_config, distribution_strategy, chief_config, worker_config, worker_count, entry_point_args, stream_logs, job_labels, service_account, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# `TF_KERAS_RUNNING_REMOTELY` env var because of an additional unknown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;31m# param.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown keyword arguments: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m# Get defaults values for input param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unknown keyword arguments: dict_keys(['docker_image_name'])"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83daf47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
